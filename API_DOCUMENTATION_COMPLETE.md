# ÙˆØ«Ø§Ø¦Ù‚ API Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ø®Ø¯Ù…Ø© Python Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© Ù„Ù„ØªÙØ±ÙŠØº Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ

## Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø¯Ù…Ø© Ù‡ÙŠ Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ© ÙŠØ¯Ø¹Ù… Ø¬Ù…ÙŠØ¹ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø±Ø§Ø­Ù„ 12.1-12.5 Ùˆ 13.1-13.5 Ù…Ø¹ Ù…ÙŠØ²Ø§Øª Ù…ØªØ·ÙˆØ±Ø© Ù„Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠØ©.

## Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

### ğŸ¯ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
- **Scene Salience**: ØªØ­Ù„ÙŠÙ„ Ø£Ù‡Ù…ÙŠØ© Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯
- **Continuity Check**: ÙØ­Øµ Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
- **Revolutionary Breakdown**: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ÙˆØ±ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
- **Semantic Synopsis**: Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
- **Prop Classification**: ØªØµÙ†ÙŠÙ Ø§Ù„Ø£Ø¯ÙˆØ§Øª
- **Wardrobe Inference**: Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ù…Ù„Ø§Ø¨Ø³
- **Cinematic Patterns**: Ø£Ù†Ù…Ø§Ø· Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©
- **Full Analysis**: ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„
- **Multi-Pass Analysis**: ØªØ­Ù„ÙŠÙ„ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ØªÙ…Ø±ÙŠØ±Ø§Øª

### âš¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
- **Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ©** Ù„Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
- **Ù†Ø¸Ø§Ù… Ø°Ø§ÙƒØ±Ø© Ù…Ø¤Ù‚ØªØ© Ø°ÙƒÙŠ** Ù…Ø¹ LRU eviction
- **Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ÙØ¹Ù„ÙŠ**
- **Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„Ù…ØªØ·ÙˆØ±Ø©**
- **Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©**
- **ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Revolutionary Engine**

## API Endpoints

### 1. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© ØªØ­Ù„ÙŠÙ„ Ø¬Ø¯ÙŠØ¯Ø©

```http
POST /api/v1/analysis
Content-Type: application/json

{
  "text": "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡",
  "component": "scene_salience",
  "context": {
    "scene_id": "scene_001",
    "previous_scenes": ["scene_000"]
  },
  "confidence_threshold": 0.8,
  "priority": "high",
  "revolutionary_mode": true,
  "quantum_analysis": true,
  "neuromorphic_processing": false,
  "swarm_intelligence": true,
  "max_iterations": 5,
  "enable_context_awareness": true,
  "adaptive_learning": true,
  "integrate_revolutionary_engine": true,
  "enable_parallel_processing": true,
  "cache_results": true
}
```

**Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
```json
{
  "job_id": "uuid-string",
  "status": "pending",
  "component": "scene_salience",
  "created_at": "2025-12-23T15:25:00Z",
  "estimated_completion": "2025-12-23T15:25:15Z",
  "queue_position": 2,
  "priority": "high"
}
```

### 2. Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©

```http
GET /api/v1/jobs/{job_id}
```

**Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
```json
{
  "job_id": "uuid-string",
  "status": "completed",
  "component": "scene_salience",
  "result": {
    "scene_importance": 0.85,
    "key_elements": ["character_development", "plot_advancement"],
    "emotional_impact": 0.9
  },
  "evidence": [
    {
      "span_start": 100,
      "span_end": 150,
      "text_excerpt": "Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø´Ø±ÙˆØ­",
      "rationale": "Ø§Ù„Ø³Ø¨Ø¨ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„",
      "confidence": 0.88,
      "evidence_type": "textual"
    }
  ],
  "confidence_score": 0.87,
  "processing_time_ms": 1250.5,
  "created_at": "2025-12-23T15:25:00Z",
  "completed_at": "2025-12-23T15:25:01Z",
  "metadata": {
    "priority": "high",
    "iterations": 5,
    "revolutionary_mode": true,
    "quantum_analysis": true,
    "cache_key": "cache-key-hash"
  }
}
```

### 3. Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù‡Ø§Ù…

```http
GET /api/v1/jobs?status=processing&limit=10&offset=0
```

**Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
```json
{
  "jobs": [
    {
      "job_id": "uuid-1",
      "status": "processing",
      "component": "scene_salience",
      "created_at": "2025-12-23T15:25:00Z",
      "priority": "high"
    }
  ],
  "total": 5,
  "limit": 10,
  "offset": 0
}
```

### 4. Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡

```http
GET /api/v1/metrics/performance
```

**Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
```json
{
  "cpu_usage": 45.2,
  "memory_usage": 67.8,
  "memory_available": 8.5,
  "active_jobs": 3,
  "completed_jobs": 127,
  "failed_jobs": 2,
  "pending_jobs": 8,
  "average_processing_time": 1150.3,
  "queue_length": 8,
  "uptime_seconds": 3600,
  "throughput_jobs_per_minute": 12.5,
  "cache_hit_rate": 78.5,
  "timestamp": "2025-12-23T15:25:00Z"
}
```

### 5. ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø´Ø§Ù…Ù„

```http
GET /api/v1/analytics/report
```

**Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
```json
{
  "total_analyses": 129,
  "component_usage": {
    "scene_salience": 45,
    "continuity_check": 32,
    "revolutionary_breakdown": 28,
    "full_analysis": 24
  },
  "success_rate": 98.4,
  "average_confidence": 0.847,
  "processing_time_stats": {
    "min": 850.2,
    "max": 3500.0,
    "mean": 1150.3,
    "median": 1050.7
  },
  "priority_distribution": {
    "low": 15,
    "normal": 78,
    "high": 32,
    "urgent": 4,
    "critical": 0
  },
  "daily_stats": {
    "2025-12-23": 129,
    "2025-12-22": 156,
    "2025-12-21": 134
  },
  "error_analysis": {
    "timeout": 1,
    "memory_error": 0,
    "processing_error": 1
  },
  "resource_utilization": {
    "cpu_avg": 42.5,
    "memory_avg": 65.2,
    "disk_io_avg": 15.8
  },
  "performance_trends": {
    "response_time": [1100, 1150, 1200, 1150, 1175],
    "throughput": [12.1, 12.5, 12.3, 12.7, 12.5]
  }
}
```

### 6. ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…

```http
GET /api/v1/health
```

**Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
```json
{
  "status": "healthy",
  "services": {
    "job_manager": "healthy",
    "cache_system": "healthy",
    "performance_monitor": "healthy",
    "revolutionary_engine": "connected"
  },
  "resources": {
    "cpu": 45.2,
    "memory": 67.8,
    "disk": 23.4
  },
  "connections": 5,
  "uptime": 3600.5,
  "version": "1.0.0",
  "timestamp": "2025-12-23T15:25:00Z"
}
```

## Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

### Ù…Ø«Ø§Ù„ 1: ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ù‡Ø¯ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ

```python
import requests
import json

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø·Ù„Ø¨
url = "http://localhost:8000/api/v1/analysis"
headers = {"Content-Type": "application/json"}

data = {
    "text": """
    Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©. Ù…ÙƒØªØ¨ Ø§Ù„Ù…Ø­Ø§Ù…ÙŠ - ØµØ¨Ø§Ø­Ø§Ù‹
    
    Ù…Ø­Ù…Ø¯ (35 Ø³Ù†Ø©ØŒ ÙŠØ±ØªØ¯ÙŠ Ø¨Ø¯Ù„Ø© Ø±Ø³Ù…ÙŠØ©) ÙŠØ¬Ù„Ø³ Ø®Ù„Ù Ù…ÙƒØªØ¨Ù‡ Ø§Ù„ÙƒØ¨ÙŠØ±.
    Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ø¯Ø§Ø± Ø®Ù„ÙÙ‡ Ø´Ù‡Ø§Ø¯Ø§Øª Ø¬Ø§Ù…Ø¹ÙŠØ© ÙˆØµÙˆØ± Ù…Ø¹ Ø´Ø®ØµÙŠØ§Øª Ù…Ù‡Ù…Ø©.
    
    (ÙŠÙ‚ØªØ±Ø¨ Ù…Ù† Ø§Ù„Ù†Ø§ÙØ°Ø© ÙˆÙŠÙ†Ø¸Ø± Ù„Ù„Ø®Ø§Ø±Ø¬)
    Ù…Ø­Ù…Ø¯: (ÙŠØªØ­Ø¯Ø« ÙÙŠ Ø§Ù„Ù‡Ø§ØªÙ) Ù†Ø¹Ù…ØŒ Ø³Ø£ÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ ÙÙŠ Ø§Ù„Ù…ÙˆØ¹Ø¯ Ø§Ù„Ù…Ø­Ø¯Ø¯.
    
    (ÙŠØ¶Ø¹ Ø§Ù„Ø³Ù…Ø§Ø¹Ø© ÙˆÙŠØªØ·Ù„Ø¹ Ø¹Ù„Ù‰ Ù…Ù„Ù Ø£Ù…Ø§Ù…Ù‡)
    """,
    "component": "scene_salience",
    "context": {
        "scene_id": "scene_001",
        "previous_scenes": ["scene_000"],
        "character_mood": "professional",
        "time_of_day": "morning"
    },
    "priority": "high",
    "revolutionary_mode": True,
    "quantum_analysis": True,
    "enable_parallel_processing": True,
    "cache_results": True
}

# Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
response = requests.post(url, headers=headers, json=data)
job_id = response.json()["job_id"]

print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù‡Ù…Ø©: {job_id}")

# Ø§Ù†ØªØ¸Ø§Ø± Ø§Ù„Ù†ØªÙŠØ¬Ø©
while True:
    status_response = requests.get(f"{url.rsplit('/', 1)[0]}/jobs/{job_id}")
    job = status_response.json()
    
    if job["status"] == "completed":
        print("âœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
        print(f"Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„: {job['result']}")
        print(f"Ù†Ù‚Ø§Ø· Ø§Ù„Ø«Ù‚Ø©: {job['confidence_score']}")
        break
    elif job["status"] == "failed":
        print("âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„!")
        print(f"Ø§Ù„Ø®Ø·Ø£: {job['error_message']}")
        break
    
    time.sleep(2)
```

### Ù…Ø«Ø§Ù„ 2: ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù… Ù…Ø¹ Ø§Ù„ØªÙƒØ§Ù…Ù„

```python
import asyncio
import aiohttp

async def advanced_analysis_example():
    async with aiohttp.ClientSession() as session:
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© ØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…
        advanced_request = {
            "text": "Ù†Øµ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø§Ù„Ø·ÙˆÙŠÙ„ Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…...",
            "component": "revolutionary_breakdown",
            "context": {
                "script_type": "feature_film",
                "genre": "drama",
                "target_audience": "adults"
            },
            "priority": "urgent",
            "revolutionary_mode": True,
            "quantum_analysis": True,
            "neuromorphic_processing": True,
            "swarm_intelligence": True,
            "max_iterations": 10,
            "enable_context_awareness": True,
            "adaptive_learning": True,
            "integrate_revolutionary_engine": True,
            "enable_parallel_processing": True,
            "cache_results": True
        }
        
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨
        async with session.post(
            "http://localhost:8000/api/v1/analysis",
            json=advanced_request
        ) as response:
            job_data = await response.json()
            job_id = job_data["job_id"]
        
        print(f"ğŸš€ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…: {job_id}")
        
        # Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ØªÙ‚Ø¯Ù…
        while True:
            async with session.get(
                f"http://localhost:8000/api/v1/jobs/{job_id}"
            ) as response:
                job = await response.json()
            
            if job["status"] == "completed":
                print("ğŸ‰ Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…!")
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ÙØµÙ„Ø©
                result = job["result"]
                print(f"Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©: {job.get('revolutionary_enhancements', {})}")
                print(f"Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ…ÙˆÙ…ÙŠ: {job.get('quantum_analysis', {})}")
                print(f"Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ©: {job.get('neuromorphic_features', {})}")
                print(f"Ø°ÙƒØ§Ø¡ Ø§Ù„Ø³Ø±Ø¨: {job.get('swarm_intelligence', {})}")
                
                break
            elif job["status"] == "failed":
                print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {job.get('error_message')}")
                break
            
            await asyncio.sleep(3)

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø«Ø§Ù„
asyncio.run(advanced_analysis_example())
```

### Ù…Ø«Ø§Ù„ 3: Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª

```python
import time
import matplotlib.pyplot as plt

def performance_monitoring_example():
    base_url = "http://localhost:8000/api/v1"
    
    # Ø¬Ù…Ø¹ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø£Ø¯Ø§Ø¡
    performance_data = []
    
    for i in range(20):  # Ù…Ø±Ø§Ù‚Ø¨Ø© Ù„Ù…Ø¯Ø© 20 Ù‚ÙŠØ§Ø³
        response = requests.get(f"{base_url}/metrics/performance")
        metrics = response.json()
        
        performance_data.append({
            "timestamp": time.time(),
            "cpu_usage": metrics["cpu_usage"],
            "memory_usage": metrics["memory_usage"],
            "active_jobs": metrics["active_jobs"],
            "throughput": metrics["throughput_jobs_per_minute"]
        })
        
        print(f"ğŸ“Š Ù‚ÙŠØ§Ø³ {i+1}: CPU={metrics['cpu_usage']:.1f}%, "
              f"Memory={metrics['memory_usage']:.1f}%, "
              f"Jobs={metrics['active_jobs']}")
        
        time.sleep(5)  # Ù‚ÙŠØ§Ø³ ÙƒÙ„ 5 Ø«ÙˆØ§Ù†
    
    # Ø±Ø³Ù… Ø§Ù„Ø£Ø¯Ø§Ø¡
    timestamps = [d["timestamp"] for d in performance_data]
    cpu_usage = [d["cpu_usage"] for d in performance_data]
    memory_usage = [d["memory_usage"] for d in performance_data]
    
    plt.figure(figsize=(12, 8))
    
    plt.subplot(2, 1, 1)
    plt.plot(timestamps, cpu_usage, label='CPU Usage %', color='red')
    plt.plot(timestamps, memory_usage, label='Memory Usage %', color='blue')
    plt.title('Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ - Ø§Ù„ÙˆÙ‚Øª')
    plt.ylabel('Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© (%)')
    plt.legend()
    
    plt.subplot(2, 1, 2)
    throughput = [d["throughput"] for d in performance_data]
    plt.plot(timestamps, throughput, label='Throughput (jobs/min)', color='green')
    plt.title('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ÙŠØ©')
    plt.xlabel('Ø§Ù„ÙˆÙ‚Øª')
    plt.ylabel('Ù…Ù‡Ø§Ù…/Ø¯Ù‚ÙŠÙ‚Ø©')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig('performance_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

# ØªØ´ØºÙŠÙ„ Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡
performance_monitoring_example()
```

## Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

### Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© ÙˆØ­Ù„ÙˆÙ„Ù‡Ø§

| ÙƒÙˆØ¯ Ø§Ù„Ø®Ø·Ø£ | Ø§Ù„ÙˆØµÙ | Ø§Ù„Ø­Ù„ |
|-----------|--------|------|
| 400 | Ø·Ù„Ø¨ ØºÙŠØ± ØµØ­ÙŠØ­ | ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±Ø³Ù„Ø© |
| 422 | Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù‚Ù‚ | ØªØ£ÙƒØ¯ Ù…Ù† Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ù…Ø®Ø·Ø· Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ |
| 429 | Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ø±ØªÙØ¹ | Ø§Ù†ØªØ¸Ø± Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„ Ø·Ù„Ø¨Ø§Øª Ø¬Ø¯ÙŠØ¯Ø© |
| 500 | Ø®Ø·Ø£ Ø¯Ø§Ø®Ù„ÙŠ ÙÙŠ Ø§Ù„Ø®Ø§Ø¯Ù… | ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø®Ø§Ø¯Ù… |
| 503 | Ø§Ù„Ø®Ø¯Ù…Ø© ØºÙŠØ± Ù…ØªØ§Ø­Ø© | ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù… |

### Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

```python
def robust_analysis_request(text, component):
    max_retries = 3
    retry_delay = 2
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                "http://localhost:8000/api/v1/analysis",
                json={
                    "text": text,
                    "component": component,
                    "priority": "normal"
                },
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()
            elif response.status_code == 429:
                print(f"âš ï¸ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ø±ØªÙØ¹ØŒ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}")
                time.sleep(retry_delay * (attempt + 1))
            else:
                print(f"âŒ Ø®Ø·Ø£ {response.status_code}: {response.text}")
                
        except requests.exceptions.Timeout:
            print(f"â° Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„ÙˆÙ‚ØªØŒ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}")
            time.sleep(retry_delay)
        except requests.exceptions.ConnectionError:
            print(f"ğŸ”Œ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ØŒ Ù…Ø­Ø§ÙˆÙ„Ø© {attempt + 1}")
            time.sleep(retry_delay)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
            break
    
    raise Exception("ÙØ´Ù„ ÙÙŠ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©")
```

## Ø§Ù„ØªÙƒÙˆÙŠÙ† ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª

### Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©

```bash
# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø§Ø¯Ù…
PORT=8000
HOST=0.0.0.0
DEBUG=False

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
MAX_CONCURRENT_JOBS=10
CACHE_TTL=3600
PERFORMANCE_THRESHOLD=1000

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
DATABASE_URL=sqlite:///./brain_service.db

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ³Ø¬ÙŠÙ„
LOG_LEVEL=INFO
LOG_FILE=logs/brain_service.log

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒØ§Ù…Ù„
REVOLUTIONARY_ENGINE_URL=http://localhost:9000
ENABLE_INTEGRATION=True
```

### ØªÙƒÙˆÙŠÙ† Ù…ØªÙ‚Ø¯Ù…

```python
# ØªØ®ØµÙŠØµ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø©
app_config = {
    "max_concurrent_jobs": 20,
    "cache_ttl": 7200,  # Ø³Ø§Ø¹ØªØ§Ù†
    "performance_threshold": 1500,
    "enable_parallel_processing": True,
    "enable_caching": True,
    "monitoring_interval": 30,
    "cleanup_interval": 3600
}
```

## Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ§Ù„Ø§Ø³ØªÙƒØ´Ø§Ù

### ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª

```bash
# ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
python comprehensive_testing_suite.py

# ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø­Ø¯Ø¯Ø©
pytest comprehensive_testing_suite.py::TestAdvancedJobManager::test_create_job_basic -v

# ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
pytest comprehensive_testing_suite.py::TestPerformanceAndLoad -v
```

### Ø§Ø³ØªÙƒØ´Ø§Ù API

```bash
# ÙØ­Øµ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„ØªÙØ§Ø¹Ù„ÙŠØ©
open http://localhost:8000/docs

# ÙØ­Øµ Ù…Ø®Ø·Ø· API
curl http://localhost:8000/openapi.json

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø§ØªØµØ§Ù„
curl http://localhost:8000/api/v1/health
```

---

## Ø§Ù„Ø¯Ø¹Ù… ÙˆØ§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©

Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ø¹Ù… Ø£Ùˆ Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Ù…Ø´Ø§ÙƒÙ„ØŒ ÙŠØ±Ø¬Ù‰ Ù…Ø±Ø§Ø¬Ø¹Ø©:
- ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ ÙÙŠ `/docs`
- Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ÙÙŠ `/logs`
- Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙÙŠ `/tests`

**Ø§Ù„Ø¥ØµØ¯Ø§Ø±**: 1.0.0  
**ØªØ§Ø±ÙŠØ® Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«**: 2025-12-23  
**Ø§Ù„Ø­Ø§Ù„Ø©**: Ø¥Ù†ØªØ§Ø¬ÙŠ âœ…
