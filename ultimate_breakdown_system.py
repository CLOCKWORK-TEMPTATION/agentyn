#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Ù†Ø¸Ø§Ù… Breakdown Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ Ø§Ù„Ø«ÙˆØ±ÙŠ - Revolutionary Breakdown System
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Ù†Ø¸Ø§Ù… Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª ÙˆØªÙˆÙ„ÙŠØ¯ Breakdown Sheets Ø§Ø­ØªØ±Ø§ÙÙŠØ©
ÙŠØ·Ø¨Ù‚ 7 ØªÙ‚Ù†ÙŠØ§Øª Ø«ÙˆØ±ÙŠØ© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø¨Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø­Ù‚ÙŠÙ‚ÙŠ

Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©: Multi-Pass Architecture (3 Ù…Ø±Ø§Ø­Ù„)
â”œâ”€â”€ Pass 1: Raw Extraction (Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ÙŠ)
â”œâ”€â”€ Pass 2: Intelligent Enrichment (Ø¥Ø«Ø±Ø§Ø¡ Ø°ÙƒÙŠ)
â””â”€â”€ Pass 3: Refinement & Validation (ØªÙ†Ù‚ÙŠØ­ ÙˆØªØ¯Ù‚ÙŠÙ‚)

Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©:
1. Semantic Synopsis Generator - Ù…ÙˆÙ„Ø¯ Ù…Ù„Ø®ØµØ§Øª Ø¯Ù„Ø§Ù„ÙŠ
2. Smart Prop Classifier - Ù…ØµÙ†Ù Ø¯Ø¹Ø§Ø¦Ù… Ø°ÙƒÙŠ
3. Wardrobe Inference Engine - Ù…Ø­Ø±Ùƒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø£Ø²ÙŠØ§Ø¡
4. Cinematic Pattern Recognition - ØªÙ…ÙŠÙŠØ² Ø£Ù†Ù…Ø§Ø· Ø¥Ø®Ø±Ø§Ø¬ÙŠØ©
5. Scene Relationship Graph - Ø´Ø¨ÙƒØ© Ø¹Ù„Ø§Ù‚Ø§Øª Ù…Ø´Ø§Ù‡Ø¯
6. Context-Aware Analysis - ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ø¹ÙŠ Ø¨Ø§Ù„Ø³ÙŠØ§Ù‚
7. Legal Alert System - Ù†Ø¸Ø§Ù… ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©

Ø§Ù„Ù…Ø¤Ù„Ù: Mohamed Amin Rady
Ø§Ù„Ø¥ØµØ¯Ø§Ø±: 3.0.0 (Revolutionary Edition)
Ø§Ù„ØªØ±Ø®ÙŠØµ: Production-Ready
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import re
import html
import asyncio
import logging
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Set, Optional, Tuple
from pathlib import Path
from enum import Enum
from collections import defaultdict

try:
    import aiofiles
    ASYNC_FILES_AVAILABLE = True
except ImportError:
    ASYNC_FILES_AVAILABLE = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¥Ø¹Ø¯Ø§Ø¯ Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ³Ø¬ÙŠÙ„ (Logging Configuration)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(name)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger("RevolutionaryBreakdown")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Domain Models)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SceneType(Enum):
    """ØªØµÙ†ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯"""
    DIALOGUE_HEAVY = "Ø­ÙˆØ§Ø±ÙŠ"
    ACTION_SEQUENCE = "Ø­Ø±ÙƒÙŠ"
    DISCOVERY = "Ø§ÙƒØªØ´Ø§Ù"
    CONFRONTATION = "Ù…ÙˆØ§Ø¬Ù‡Ø©"
    TRANSITION = "Ø§Ù†ØªÙ‚Ø§Ù„ÙŠ"
    EMOTIONAL = "Ø¹Ø§Ø·ÙÙŠ"


@dataclass
class CharacterProfile:
    """Ù…Ù„Ù Ø´Ø®ØµÙŠ ÙƒØ§Ù…Ù„ Ù„Ù„Ø´Ø®ØµÙŠØ©"""
    name: str
    full_name: str
    gender: str = "unknown"
    age_range: str = ""
    profession: str = ""
    social_class: str = ""
    psychological_state: str = ""


@dataclass
class WardrobeSpec:
    """Ù…ÙˆØ§ØµÙØ§Øª Ø²ÙŠ ØªÙØµÙŠÙ„ÙŠØ©"""
    character: str
    description: str
    is_inferred: bool = True
    continuity_note: str = ""


@dataclass
class LegalAlert:
    """ØªÙ†Ø¨ÙŠÙ‡ Ù‚Ø§Ù†ÙˆÙ†ÙŠ"""
    alert_type: str  # "celebrity", "brand", "music", "trademark"
    entity_name: str
    description: str
    severity: str = "warning"  # "warning", "critical"


@dataclass
class DetailedBreakdown:
    """Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù€ Breakdown Sheet"""
    # === Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ===
    scene_number: str
    int_ext: str
    day_night: str
    location: str
    scene_type: SceneType = SceneType.TRANSITION
    
    # === Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø´Ù‡Ø¯ ===
    summary: str = ""
    original_text: str = ""  # Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„Ù…Ø´Ù‡Ø¯
    
    # === Ø·Ø§Ù‚Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ ===
    cast: List[str] = field(default_factory=list)
    cast_profiles: Dict[str, CharacterProfile] = field(default_factory=dict)
    extras_html: str = ""
    
    # === Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ ÙˆØ§Ù„Ù…ÙƒÙŠØ§Ø¬ (ØªÙØµÙŠÙ„ÙŠ) ===
    wardrobe_specs: List[WardrobeSpec] = field(default_factory=list)
    costumes_html: str = ""
    makeup_html: str = ""
    
    # === Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù… ÙˆØ§Ù„Ø¯ÙŠÙƒÙˆØ± ===
    props_list: List[str] = field(default_factory=list)
    props_html: str = ""
    set_dressing_html: str = ""
    
    # === Ø¹Ù†Ø§ØµØ± Ø¥Ù†ØªØ§Ø¬ÙŠØ© ===
    animals: str = "Ù„Ø§ ÙŠÙˆØ¬Ø¯"
    vehicles: str = "Ù„Ø§ ÙŠÙˆØ¬Ø¯"
    greenery: str = "Ù„Ø§ ÙŠÙˆØ¬Ø¯"
    stunts: str = "Ù„Ø§ ÙŠÙˆØ¬Ø¯"
    
    # === Ø§Ù„Ù…Ø¤Ø«Ø±Ø§Øª ===
    special_effects_html: str = ""
    visual_effects: str = "Ù„Ø§ ÙŠÙˆØ¬Ø¯"
    sound_html: str = ""
    
    # === Ø§Ù„ØªØµÙˆÙŠØ± ===
    camera_lighting: str = ""
    
    # === Ø§Ù„Ù…Ù„Ø§Ø­Ø¸Ø§Øª ===
    production_notes: str = ""
    production_notes_html: str = ""
    cinematic_notes: str = ""
    continuity_notes: List[str] = field(default_factory=list)
    legal_alerts: List[LegalAlert] = field(default_factory=list)
    
    # === Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØµÙÙŠØ© ===
    is_continuation: bool = False
    previous_scene_ref: Optional[str] = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© (Knowledge Bases)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class KnowledgeBase:
    """Ù‚Ø§Ø¹Ø¯Ø© Ù…Ø¹Ø±ÙÙŠØ© Ù…Ø±ÙƒØ²ÙŠØ© Ù„Ù„Ù†Ø¸Ø§Ù…"""
    
    # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©
    KNOWN_CHARACTERS: Dict[str, CharacterProfile] = {
        "Ù†Ù‡Ø§Ù„": CharacterProfile(
            name="Ù†Ù‡Ø§Ù„",
            full_name="Ù†Ù‡Ø§Ù„ Ø³Ù…Ø§Ø­Ø©",
            gender="female",
            age_range="30s",
            social_class="Ù…ØªÙˆØ³Ø·Ø©-Ø¹Ù„ÙŠØ§",
            psychological_state="Ù‚Ù„Ù‚Ø©/ØµØ§Ø±Ù…Ø©"
        ),
        "Ù†ÙˆØ±": CharacterProfile(
            name="Ù†ÙˆØ±",
            full_name="Ù†ÙˆØ± ØªÙˆÙÙŠÙ‚",
            gender="female",
            age_range="30s",
            profession="Ù…Ù…Ø«Ù„Ø©",
            social_class="Ø¹Ù„ÙŠØ§"
        ),
        "ÙƒØ±ÙŠÙ…": CharacterProfile(
            name="ÙƒØ±ÙŠÙ…",
            full_name="ÙƒØ±ÙŠÙ… Ø±Ø²Ù‚",
            gender="male",
            age_range="50s",
            profession="Ù…Ù†ØªØ¬",
            social_class="Ø¹Ù„ÙŠØ§"
        ),
        "Ù…Ø¯Ø­Øª": CharacterProfile(
            name="Ù…Ø¯Ø­Øª",
            full_name="Ù…Ø¯Ø­Øª Ù…Ø­ÙÙˆØ¸",
            gender="male",
            age_range="30s",
            profession="Ù…Ø¨Ø§Ø­Ø« Ø£Ù…Ù† Ø¯ÙˆÙ„Ø©",
            social_class="Ù…ØªÙˆØ³Ø·Ø©"
        ),
        "Ø·Ø§Ø±Ù‚": CharacterProfile(
            name="Ø·Ø§Ø±Ù‚",
            full_name="Ø·Ø§Ø±Ù‚ ÙŠØ­ÙŠ",
            gender="male",
            age_range="40s",
            profession="Ø¥Ø¹Ù„Ø§Ù…ÙŠ Ø¯ÙŠÙ†ÙŠ",
            social_class="Ù…ØªÙˆØ³Ø·Ø©-Ø¹Ù„ÙŠØ§"
        ),
        "Ø£Ù…ÙŠØ±Ø©": CharacterProfile(
            name="Ø£Ù…ÙŠØ±Ø©",
            full_name="Ø£Ù…ÙŠØ±Ø© Ø­Ø´Ù…Øª",
            gender="female",
            age_range="30s",
            social_class="Ø¹Ù„ÙŠØ§"
        ),
        "Ø§Ù…ÙŠØ±Ø©": CharacterProfile(
            name="Ø§Ù…ÙŠØ±Ø©",
            full_name="Ø£Ù…ÙŠØ±Ø© Ø­Ø´Ù…Øª",
            gender="female",
            age_range="30s",
            social_class="Ø¹Ù„ÙŠØ§"
        ),
        "Ø±Ø£ÙØª": CharacterProfile(
            name="Ø±Ø£ÙØª",
            full_name="Ø±Ø£ÙØª ÙØ±ÙŠØ¯",
            gender="male",
            age_range="40s",
            social_class="Ø¹Ù„ÙŠØ§",
            psychological_state="Ù…Ø´Ù„ÙˆÙ„"
        ),
        "Ø±Ø§ÙØª": CharacterProfile(
            name="Ø±Ø§ÙØª",
            full_name="Ø±Ø£ÙØª ÙØ±ÙŠØ¯",
            gender="male",
            age_range="40s",
            social_class="Ø¹Ù„ÙŠØ§",
            psychological_state="Ù…Ø´Ù„ÙˆÙ„"
        ),
    }
    
    # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø´Ø§Ù‡ÙŠØ± (Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©)
    CELEBRITY_NAMES: Set[str] = {
        "Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨", "ØªØ§Ù…Ø± Ø­Ø³Ù†ÙŠ", "ØªØ§Ù…Ø± Ø­Ø³Ù†", "Ù…Ø­Ù…Ø¯ Ù…Ù†ÙŠØ±",
        "Ø£Ù†ØºØ§Ù…", "Ø´ÙŠØ±ÙŠÙ†", "Ø¹Ù…Ø±Ùˆ Ù…ØµØ·ÙÙ‰", "Ø­Ù…ÙŠØ¯ Ø§Ù„Ø´Ø§Ø¹Ø±ÙŠ",
        "Ø¹ÙƒØ§Ø´Ø©", "Ø£Ø³Ø§Ù…Ø© Ø£Ù†ÙˆØ± Ø¹ÙƒØ§Ø´Ø©", "ÙŠÙˆØ³Ù Ø´Ø§Ù‡ÙŠÙ†"
    }
    
    # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©
    BRAND_NAMES: Set[str] = {
        "Ø¢ÙŠÙÙˆÙ†", "iphone", "Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬", "samsung",
        "Ù…Ø±Ø³ÙŠØ¯Ø³", "mercedes", "Ø¨ÙŠ Ø¥Ù… Ø¯Ø¨Ù„ÙŠÙˆ", "bmw",
        "ÙÙŠØ³Ø¨ÙˆÙƒ", "facebook", "ÙˆØ§ØªØ³Ø§Ø¨", "whatsapp",
        "ØªÙˆÙŠØªØ±", "twitter", "Ø¥Ù†Ø³ØªØ¬Ø±Ø§Ù…", "instagram"
    }
    
    # Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ø³Ù…Ø§Ø¡ Ø£ØºØ§Ù†ÙŠ (Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª)
    SONG_TITLES: Set[str] = {
        "Ø¨Ø¹Ø¯Øª Ù„ÙŠÙ‡", "ØªÙ…Ù„ÙŠ Ù…Ø¹Ø§Ùƒ", "Ù‚Ù„Ø¨ÙŠ Ø§Ø®ØªØ§Ø±Ùƒ",
        "Ù…Ø¹Ø§Ùƒ Ù‚Ù„Ø¨ÙŠ", "Ø£Ù†Ø§ Ù„ÙŠÙ„Ø©", "Ù†ÙˆØ± Ø§Ù„Ø¹ÙŠÙ†"
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªÙ‚Ù†ÙŠØ© 1: Semantic Synopsis Generator (Ù…ÙˆÙ„Ø¯ Ù…Ù„Ø®ØµØ§Øª Ø¯Ù„Ø§Ù„ÙŠ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SynopsisGenerator:
    """
    Ù…ÙˆÙ„Ø¯ Ù…Ù„Ø®ØµØ§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø­Ø±ÙÙŠ
    ÙŠØ³ØªØ®Ø¯Ù… Ù‚ÙˆØ§Ù„Ø¨ Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ© + Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ù„Ø§Ù„ÙŠ
    """
    
    # Ù‚ÙˆØ§Ù„Ø¨ Ø¬Ù…Ù„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯
    TEMPLATES = {
        SceneType.DIALOGUE_HEAVY: [
            "{char1} Ùˆ{char2} ÙŠØªØ­Ø§ÙˆØ±Ø§Ù† Ø­ÙˆÙ„ {topic}",
            "Ø­ÙˆØ§Ø± Ø¨ÙŠÙ† {char1} Ùˆ{char2} ÙŠÙƒØ´Ù {insight}",
            "Ù†Ù‚Ø§Ø´ Ø­Ø§Ø¯ Ø¨ÙŠÙ† {char1} Ùˆ{char2} Ø¨Ø´Ø£Ù† {issue}"
        ],
        SceneType.ACTION_SEQUENCE: [
            "{character} {action} ÙÙŠ {location}",
            "{character} {action} Ø¨ÙŠÙ†Ù…Ø§ {context}",
            "ØªØªØ§Ø¨Ø¹ Ø£Ø­Ø¯Ø§Ø«: {character} {action}"
        ],
        SceneType.DISCOVERY: [
            "{character} {discover_verb} {object}",
            "{character} ÙŠØ¹Ø«Ø± Ø¹Ù„Ù‰ {object} {location_detail}",
            "Ù„Ø­Ø¸Ø© Ø§ÙƒØªØ´Ø§Ù: {character} {discover_verb} {object}"
        ],
        SceneType.CONFRONTATION: [
            "Ù…ÙˆØ§Ø¬Ù‡Ø© Ø¨ÙŠÙ† {char1} Ùˆ{char2} Ø­ÙˆÙ„ {issue}",
            "{char1} ÙŠØªØ­Ø¯Ù‰ {char2} ÙÙŠ {context}",
            "ØµØ±Ø§Ø¹ Ø¨ÙŠÙ† {char1} Ùˆ{char2} ÙŠÙƒØ´Ù {revelation}"
        ],
        SceneType.EMOTIONAL: [
            "{character} ÙÙŠ Ø­Ø§Ù„Ø© {emotion}",
            "Ù„Ø­Ø¸Ø© Ø¹Ø§Ø·ÙÙŠØ©: {character} {emotional_action}",
            "{character} {emotion_verb} Ø¨Ø³Ø¨Ø¨ {reason}"
        ],
        SceneType.TRANSITION: [
            "Ø§Ù†ØªÙ‚Ø§Ù„ Ø¥Ù„Ù‰ {location}",
            "{character} {action} ÙÙŠ {location}",
            "Ù…Ø´Ù‡Ø¯ Ø§Ù†ØªÙ‚Ø§Ù„ÙŠ ÙŠÙØ¸Ù‡Ø± {context}"
        ]
    }
    
    # Ø£ÙØ¹Ø§Ù„ Ø­Ø±ÙƒÙŠØ©
    ACTION_VERBS = {
        "ÙŠØ¯Ø®Ù„", "ÙŠØ®Ø±Ø¬", "ÙŠØªØ¬Ù‡", "ÙŠÙ…Ø´ÙŠ", "ÙŠØ¬Ø±ÙŠ", "ÙŠÙ‚ÙˆØ¯",
        "ÙŠØ¬Ù„Ø³", "ÙŠÙ†Ù‡Ø¶", "ÙŠÙØªØ­", "ÙŠØºÙ„Ù‚", "ÙŠØ£Ø®Ø°", "ÙŠØ¶Ø¹"
    }
    
    # Ø£ÙØ¹Ø§Ù„ Ø§ÙƒØªØ´Ø§Ù
    DISCOVERY_VERBS = {
        "ÙŠØ¬Ø¯", "ÙŠÙ„Ù…Ø­", "ÙŠÙƒØªØ´Ù", "ÙŠØ¹Ø«Ø± Ø¹Ù„Ù‰", "ØªÙ‚Ø¹ Ø¹ÙŠÙ†Ù‡ Ø¹Ù„Ù‰",
        "ÙŠÙ„Ø§Ø­Ø¸", "ÙŠØ±Ù‰", "ÙŠØ´Ø§Ù‡Ø¯"
    }
    
    def generate_synopsis(self, scene_text: str, scene_type: SceneType,
                         characters: List[str]) -> str:
        """
        ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ
        
        Args:
            scene_text: Ø§Ù„Ù†Øµ Ø§Ù„Ø£ØµÙ„ÙŠ Ù„Ù„Ù…Ø´Ù‡Ø¯
            scene_type: Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø§Ù„Ù…ÙØµÙ†Ù
            characters: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø´Ø®ØµÙŠØ§Øª
            
        Returns:
            Ù…Ù„Ø®Øµ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù…ÙˆØ¬Ø²
        """
        try:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ©
            entities = self._extract_semantic_entities(scene_text, characters)
            
            # Ø§Ø®ØªÙŠØ§Ø± Ù‚Ø§Ù„Ø¨ Ù…Ù†Ø§Ø³Ø¨
            template = self._select_template(scene_type, entities)
            
            # Ù…Ù„Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨
            synopsis = self._fill_template(template, entities)
            
            # ØªÙ†Ù‚ÙŠØ­ Ù†Ù‡Ø§Ø¦ÙŠ
            synopsis = self._refine_synopsis(synopsis, scene_text)
            
            return synopsis
            
        except Exception as e:
            logger.warning(f"ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {e}")
            # Fallback: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ·
            return self._fallback_summary(scene_text)
    
    def _extract_semantic_entities(self, text: str, 
                                   characters: List[str]) -> Dict:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""
        entities = {
            'characters': characters[:2] if len(characters) >= 2 else characters,
            'main_char': characters[0] if characters else "Ø§Ù„Ø´Ø®ØµÙŠØ©",
            'action': self._extract_main_action(text),
            'object': self._extract_object(text),
            'location_detail': self._extract_location_detail(text),
            'emotion': self._extract_emotion(text),
            'topic': self._extract_topic(text)
        }
        return entities
    
    def _extract_main_action(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙØ¹Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ"""
        text_lower = text.lower()
        for verb in self.ACTION_VERBS:
            if verb in text_lower:
                return verb
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø£ÙØ¹Ø§Ù„ Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
        for verb in self.DISCOVERY_VERBS:
            if verb in text_lower:
                return verb
        
        return "ÙŠØªÙØ§Ø¹Ù„"
    
    def _extract_object(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…Ø­ÙˆØ±ÙŠ ÙÙŠ Ø§Ù„Ù…Ø´Ù‡Ø¯"""
        # Ø¨Ø­Ø« Ø¹Ù† Ø¯Ø¹Ø§Ø¦Ù… Ù…Ù‡Ù…Ø©
        objects = [
            ("Ø¸Ø±Ù", r"Ø¸Ø±Ù"),
            ("Ù‡Ø§ØªÙ Ù…Ø­Ù…ÙˆÙ„", r"Ù‡Ø§ØªÙ|Ù…ÙˆØ¨Ø§ÙŠÙ„"),
            ("Ù„Ø§Ø¨ØªÙˆØ¨", r"Ù„Ø§Ø¨ØªÙˆØ¨|Ø­Ø§Ø³Ø¨\s*(?:Ø¢Ù„ÙŠ|Ø§Ù„ÙŠ)"),
            ("ØµÙˆØ±Ø©", r"ØµÙˆØ±Ø©"),
            ("Ù…Ø³ØªÙ†Ø¯", r"Ù…Ø³ØªÙ†Ø¯|ÙˆØ±Ù‚|Ù…Ù„Ù")
        ]
        
        for obj_name, pattern in objects:
            if re.search(pattern, text, re.I):
                return obj_name
        
        return "Ø´ÙŠØ¡ Ù…Ø§"
    
    def _extract_location_detail(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…ÙˆÙ‚Ø¹"""
        locations = [
            ("Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙƒØªØ¨", r"Ø¹Ù„Ù‰.*Ù…ÙƒØªØ¨|ÙÙˆÙ‚.*Ù…ÙƒØªØ¨"),
            ("ØªØ­Øª Ø§Ù„Ù…Ø³Ø§Ø­Ø§Øª", r"ØªØ­Øª.*Ù…Ø³Ø§Ø­"),
            ("Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø§Ø´Ø©", r"Ø¹Ù„Ù‰.*Ø´Ø§Ø´Ø©|Ø¹Ù„Ù‰.*Ø­Ø§Ø³Ø¨"),
            ("ÙÙŠ Ø§Ù„ØºØ±ÙØ©", r"ÙÙŠ.*ØºØ±ÙØ©"),
            ("ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ø±Ø©", r"ÙÙŠ.*Ø³ÙŠØ§Ø±Ø©")
        ]
        
        for detail, pattern in locations:
            if re.search(pattern, text, re.I):
                return detail
        
        return ""
    
    def _extract_emotion(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø¹Ø§Ø·ÙÙŠØ©"""
        emotions = [
            ("Ù‚Ù„Ù‚ Ø´Ø¯ÙŠØ¯", r"Ù‚Ù„Ù‚|Ù‚Ù„Ù‚Ø©|Ù…ØªÙˆØªØ±|Ù…ØªÙˆØªØ±Ø©"),
            ("Ø¥Ø­Ø¨Ø§Ø·", r"Ø¥Ø­Ø¨Ø§Ø·|Ù…Ø­Ø¨Ø·|Ù…Ø­Ø¨Ø·Ø©|Ø¶ÙŠÙ‚"),
            ("ØºØ¶Ø¨", r"ØºØ¶Ø¨|ØºØ§Ø¶Ø¨|ØºØ§Ø¶Ø¨Ø©|Ø­Ø¯Ø©"),
            ("Ø§Ø³ØªØºØ±Ø§Ø¨", r"Ø§Ø³ØªØºØ±Ø§Ø¨|Ù…Ø³ØªØºØ±Ø¨|ÙŠØ³ØªØºØ±Ø¨"),
            ("Ø³Ø¹Ø§Ø¯Ø©", r"Ø³Ø¹Ø§Ø¯Ø©|Ø³Ø¹ÙŠØ¯|Ø³Ø¹ÙŠØ¯Ø©|ÙØ±Ø­")
        ]
        
        for emotion, pattern in emotions:
            if re.search(pattern, text, re.I):
                return emotion
        
        return "Ø­Ø§Ù„Ø© Ø¹Ø§Ø·ÙÙŠØ© Ù…Ø¹ÙŠÙ†Ø©"
    
    def _extract_topic(self, text: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø­ÙˆØ±ÙŠ ÙÙŠ Ø§Ù„Ø­ÙˆØ§Ø±"""
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„Ø­ÙˆØ§Ø± Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
        dialogue_pattern = r':\s*([^\n]{20,100})'
        dialogues = re.findall(dialogue_pattern, text)
        
        if dialogues:
            # ØªØ­Ù„ÙŠÙ„ Ø£ÙˆÙ„ Ø³Ø·Ø± Ø­ÙˆØ§Ø± Ù„Ù„Ù…ÙˆØ¶ÙˆØ¹
            first_dialogue = dialogues[0].lower()
            
            if "ØªÙ„ÙØ²ÙŠÙˆÙ†" in first_dialogue or "ÙÙŠÙ„Ù…" in first_dialogue:
                return "Ù…Ø³ØªÙ‚Ø¨Ù„ Ù…Ù‡Ù†ÙŠ"
            elif "Ø¹Ù…Ø±Ùˆ Ø¯ÙŠØ§Ø¨" in first_dialogue or "ØªØ§Ù…Ø±" in first_dialogue:
                return "Ø¥Ø­ÙŠØ§Ø¡ Ù…Ù†Ø§Ø³Ø¨Ø©"
            elif "Ù…Ø¸Ø§Ù‡Ø±Ø©" in first_dialogue:
                return "Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø£Ù…Ù†ÙŠ"
            else:
                return "Ù…ÙˆØ¶ÙˆØ¹ Ø®Ø§Øµ"
        
        return "Ù…ÙˆØ¶ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯"
    
    def _select_template(self, scene_type: SceneType, 
                        entities: Dict) -> str:
        """Ø§Ø®ØªÙŠØ§Ø± Ù‚Ø§Ù„Ø¨ Ù…Ù†Ø§Ø³Ø¨"""
        templates = self.TEMPLATES.get(scene_type, 
                                      self.TEMPLATES[SceneType.TRANSITION])
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙˆÙØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        for template in templates:
            required_keys = re.findall(r'\{(\w+)\}', template)
            if all(entities.get(k) for k in required_keys):
                return template
        
        # Fallback Ù„Ù„Ù‚Ø§Ù„Ø¨ Ø§Ù„Ø£ÙˆÙ„
        return templates[0]
    
    def _fill_template(self, template: str, entities: Dict) -> str:
        """Ù…Ù„Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨ Ø¨Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ù…Ù„Ø¡ Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
            filled = template
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø´Ø®ØµÙŠØ§Øª
            if '{char1}' in filled and len(entities['characters']) >= 1:
                filled = filled.replace('{char1}', entities['characters'][0])
            if '{char2}' in filled and len(entities['characters']) >= 2:
                filled = filled.replace('{char2}', entities['characters'][1])
            if '{character}' in filled:
                filled = filled.replace('{character}', entities['main_char'])
            
            # Ù…Ù„Ø¡ Ø¨Ù‚ÙŠØ© Ø§Ù„Ø­Ù‚ÙˆÙ„
            for key, value in entities.items():
                if f'{{{key}}}' in filled and value:
                    filled = filled.replace(f'{{{key}}}', str(value))
            
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ placeholders Ù…ØªØ¨Ù‚ÙŠØ©
            filled = re.sub(r'\{[^}]+\}', '...', filled)
            
            return filled
            
        except Exception as e:
            logger.warning(f"Ø®Ø·Ø£ ÙÙŠ Ù…Ù„Ø¡ Ø§Ù„Ù‚Ø§Ù„Ø¨: {e}")
            return template
    
    def _refine_synopsis(self, synopsis: str, original_text: str) -> str:
        """ØªÙ†Ù‚ÙŠØ­ Ø§Ù„Ù…Ù„Ø®Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        # ØªÙ†Ø¸ÙŠÙ
        synopsis = synopsis.strip()
        
        # Ø¥Ø¶Ø§ÙØ© Ù†Ù‚Ø·Ø© Ù†Ù‡Ø§Ø¦ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù…
        if not synopsis.endswith(('.', 'ØŸ', '!')):
            synopsis += '.'
        
        # Ø¶Ù…Ø§Ù† Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        if len(synopsis) > 250:
            synopsis = synopsis[:247] + '...'
        
        return synopsis
    
    def _fallback_summary(self, text: str) -> str:
        """Ù…Ù„Ø®Øµ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¨Ø³ÙŠØ·"""
        lines = [l.strip() for l in text.split('\n') if l.strip()]
        
        # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£ÙˆÙ„ (header) ÙˆØ§Ù„Ø­ÙˆØ§Ø±Ø§Øª
        summary_lines = []
        for line in lines[1:]:
            if re.match(r'^[^\n:]{1,40}:', line):
                continue
            if len(line) < 15:
                continue
            summary_lines.append(line)
            if len(' '.join(summary_lines)) > 200:
                break
        
        summary = ' '.join(summary_lines)
        return summary[:247] + '...' if len(summary) > 250 else summary


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªÙ‚Ù†ÙŠØ© 2: Smart Prop Classifier (Ù…ØµÙ†Ù Ø¯Ø¹Ø§Ø¦Ù… Ø°ÙƒÙŠ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PropClassifier:
    """
    Ù…ØµÙ†Ù Ø°ÙƒÙŠ Ù„Ù„Ø¯Ø¹Ø§Ø¦Ù… Ø­Ø³Ø¨ ÙˆØ¸ÙŠÙØªÙ‡Ø§ ÙÙŠ Ø§Ù„Ù…Ø´Ù‡Ø¯
    ÙŠÙ…Ù†Ø¹ Ø£Ø®Ø·Ø§Ø¡ Ù…Ø«Ù„: ÙƒØ±Ø³ÙŠ Ù…ØªØ­Ø±Ùƒ â†’ Vehicles
    """
    
    # ØªØµÙ†ÙŠÙ Ù‡Ø±Ù…ÙŠ Ù„Ù„Ø£Ø´ÙŠØ§Ø¡
    TAXONOMY = {
        'props': {
            'keywords': ['ÙŠÙ…Ø³Ùƒ', 'ÙŠØ£Ø®Ø°', 'ÙŠÙ†Ø§ÙˆÙ„', 'ÙŠØ­Ù…Ù„', 'Ù…Ø­Ù…ÙˆÙ„', 
                        'ØµØºÙŠØ±', 'Ø®ÙÙŠÙ', 'ÙÙŠ ÙŠØ¯Ù‡'],
            'patterns': [
                r'Ø¸Ø±Ù|Ù…Ø¸Ø±ÙˆÙ',
                r'Ù‡Ø§ØªÙ|Ù…ÙˆØ¨Ø§ÙŠÙ„|ØªÙ„ÙŠÙÙˆÙ†(?!\s+Ù…Ø­Ù…ÙˆÙ„\s+Ø¢Ù„ÙŠ)',
                r'Ù…Ø¬Ù„Ø©|ØµØ­ÙŠÙØ©',
                r'Ø­Ù‚ÙŠØ¨Ø©|Ø´Ù†Ø·Ø©',
                r'ÙƒØ£Ø³|ÙƒÙˆØ¨|ÙÙ†Ø¬Ø§Ù†',
                r'Ù…ÙØªØ§Ø­|Ù…ÙØ§ØªÙŠØ­',
                r'Ù†Ø¸Ø§Ø±Ø©|Ù†Ø¸Ø§Ø±Ø§Øª',
                r'Ø³Ø§Ø¹Ø©\s+(?:ÙŠØ¯|Ø­Ø§Ø¦Ø·)',
            ],
            'medical_devices': [
                r'ÙƒØ±Ø³ÙŠ\s+Ù…ØªØ­Ø±Ùƒ(?:\s+Ø·Ø¨ÙŠ)?',
                r'Ø¹ÙƒØ§Ø²|Ø¹ÙƒØ§Ø²Ø©',
                r'Ø­Ø¨ÙˆØ¨|Ø¯ÙˆØ§Ø¡|Ø¹Ù„Ø§Ø¬',
            ]
        },
        'set_dressing': {
            'keywords': ['ÙŠØ¬Ù„Ø³ Ø¹Ù„Ù‰', 'Ø£Ù…Ø§Ù…', 'Ø®Ù„Ù', 'Ø¨Ø¬ÙˆØ§Ø±', 'Ø«Ø§Ø¨Øª',
                        'Ø¯ÙŠÙƒÙˆØ±', 'Ø£Ø«Ø§Ø«'],
            'patterns': [
                r'ÙƒØ±Ø³ÙŠ(?!\s+Ù…ØªØ­Ø±Ùƒ)',  # ÙƒØ±Ø³ÙŠ Ø¹Ø§Ø¯ÙŠ ÙÙ‚Ø·
                r'Ø·Ø§ÙˆÙ„Ø©|Ù…Ù†Ø¶Ø¯Ø©',
                r'Ù…Ø±Ø¢Ø©|Ù…Ø±Ø§ÙŠØ©',
                r'Ø³Ø±ÙŠØ±',
                r'Ø®Ø²Ø§Ù†Ø©|Ø¯ÙˆÙ„Ø§Ø¨',
                r'Ø±Ù|Ø£Ø±ÙÙ',
                r'Ù„ÙˆØ­Ø©|Ù„ÙˆØ­Ø§Øª',
                r'Ø³ØªØ§Ø±Ø©|Ø³ØªØ§Ø¦Ø±',
            ]
        },
        'vehicles': {
            'keywords': ['ÙŠØ¯Ø®Ù„ Ø¥Ù„Ù‰', 'ÙŠÙ‚ÙˆØ¯', 'ÙŠØ±ÙƒØ¨', 'Ø¹Ø¬Ù„Ø§Øª', 'Ù…Ø­Ø±Ùƒ',
                        'ÙŠØªØ­Ø±Ùƒ', 'Ø³Ø±Ø¹Ø©'],
            'patterns': [
                r'Ø³ÙŠØ§Ø±Ø©(?!\s+Ù„Ø¹Ø¨Ø©)',
                r'Ø¯Ø±Ø§Ø¬Ø©(?:\s+Ù†Ø§Ø±ÙŠØ©|\s+Ø¨Ø®Ø§Ø±ÙŠØ©)?',
                r'Ø·Ø§Ø¦Ø±Ø©',
                r'Ù‚Ø§Ø±Ø¨|Ù…Ø±ÙƒØ¨',
                r'Ø­Ø§ÙÙ„Ø©|Ø£ØªÙˆØ¨ÙŠØ³',
            ]
        }
    }
    
    def classify_prop(self, item: str, context: str) -> Tuple[str, str]:
        """
        ØªØµÙ†ÙŠÙ Ø§Ù„Ø¯Ø¹Ù…Ø© Ø¨Ø°ÙƒØ§Ø¡
        
        Args:
            item: Ø§Ø³Ù… Ø§Ù„Ø´ÙŠØ¡
            context: Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­ÙŠØ· (Ø¬Ù…Ù„Ø© Ø£Ùˆ ÙÙ‚Ø±Ø©)
            
        Returns:
            (category, item_name) - Ø§Ù„ÙØ¦Ø© ÙˆØ§Ù„Ø§Ø³Ù… Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
        """
        item_lower = item.lower()
        context_lower = context.lower()
        
        # Ø­Ø§Ù„Ø© Ø®Ø§ØµØ©: Ø§Ù„ÙƒØ±Ø³ÙŠ Ø§Ù„Ù…ØªØ­Ø±Ùƒ
        if re.search(r'ÙƒØ±Ø³ÙŠ\s+Ù…ØªØ­Ø±Ùƒ', item_lower):
            return self._classify_wheelchair(context_lower)
        
        # ØªØµÙ†ÙŠÙ Ø¹Ø§Ù…
        for category, rules in self.TAXONOMY.items():
            # ÙØ­Øµ Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            for pattern in rules.get('patterns', []):
                if re.search(pattern, item_lower):
                    # ØªØ£ÙƒÙŠØ¯ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚
                    keyword_match = any(kw in context_lower 
                                       for kw in rules['keywords'])
                    if keyword_match or category == 'props':
                        return category, self._enhance_item_name(item, category)
            
            # ÙØ­Øµ medical devices ÙÙŠ props
            if category == 'props':
                for pattern in rules.get('medical_devices', []):
                    if re.search(pattern, item_lower):
                        return 'props', self._enhance_item_name(item, 'props')
        
        # Ø§ÙØªØ±Ø§Ø¶ÙŠ: props
        return 'props', item
    
    def _classify_wheelchair(self, context: str) -> Tuple[str, str]:
        """ØªØµÙ†ÙŠÙ Ø°ÙƒÙŠ Ù„Ù„ÙƒØ±Ø³ÙŠ Ø§Ù„Ù…ØªØ­Ø±Ùƒ"""
        # Ø§Ù„ÙƒØ±Ø³ÙŠ Ø§Ù„Ù…ØªØ­Ø±Ùƒ Ø§Ù„Ø·Ø¨ÙŠ = Props (Ø£Ø¯Ø§Ø© Ø·Ø¨ÙŠØ©)
        # Ø¥Ù„Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ ÙŠØ´ÙŠØ± Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ ÙƒÙ…Ø±ÙƒØ¨Ø©
        
        vehicle_indicators = ['ÙŠØ¯ÙØ¹', 'Ø³Ø±Ø¹Ø©', 'ÙŠØªØ­Ø±Ùƒ', 'Ø·Ø±ÙŠÙ‚', 'Ø´Ø§Ø±Ø¹']
        medical_indicators = ['Ø·Ø¨ÙŠ', 'Ù…Ø±ÙŠØ¶', 'ÙŠØ¬Ù„Ø³', 'Ù…Ø´Ù„ÙˆÙ„', 'Ø¥Ø¹Ø§Ù‚Ø©']
        
        vehicle_score = sum(1 for ind in vehicle_indicators if ind in context)
        medical_score = sum(1 for ind in medical_indicators if ind in context)
        
        if vehicle_score > medical_score and vehicle_score >= 2:
            return 'vehicles', 'ÙƒØ±Ø³ÙŠ Ù…ØªØ­Ø±Ùƒ'
        else:
            # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: Props (Ø£Ø¯Ø§Ø© Ø·Ø¨ÙŠØ©)
            return 'props', 'ÙƒØ±Ø³ÙŠ Ù…ØªØ­Ø±Ùƒ Ø·Ø¨ÙŠ'
    
    def _enhance_item_name(self, item: str, category: str) -> str:
        """ØªØ­Ø³ÙŠÙ† Ø§Ø³Ù… Ø§Ù„Ø¯Ø¹Ù…Ø©"""
        enhancements = {
            'props': {
                'Ø¸Ø±Ù': 'Ø¸Ø±Ù Ø¨Ø±ÙŠØ¯ÙŠ',
                'Ù‡Ø§ØªÙ': 'Ù‡Ø§ØªÙ Ù…Ø­Ù…ÙˆÙ„',
                'Ù…ÙˆØ¨Ø§ÙŠÙ„': 'Ù‡Ø§ØªÙ Ù…Ø­Ù…ÙˆÙ„',
                'Ø­Ø§Ø³Ø¨': 'Ø­Ø§Ø³Ø¨ Ø¢Ù„ÙŠ Ù…Ø­Ù…ÙˆÙ„',
                'Ù„Ø§Ø¨ØªÙˆØ¨': 'Ø­Ø§Ø³Ø¨ Ø¢Ù„ÙŠ Ù…Ø­Ù…ÙˆÙ„ (Ù„Ø§Ø¨ØªÙˆØ¨)',
            }
        }
        
        item_lower = item.lower().strip()
        category_enhancements = enhancements.get(category, {})
        
        for key, enhanced in category_enhancements.items():
            if key in item_lower:
                return enhanced
        
        return item


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªÙ‚Ù†ÙŠØ© 3: Wardrobe Inference Engine (Ù…Ø­Ø±Ùƒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class WardrobeInferenceEngine:
    """
    Ù…Ø­Ø±Ùƒ Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ Ù…Ù† Ø§Ù„ÙˆØµÙ ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
    Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
    """
    
    # Ù‚Ø§Ù…ÙˆØ³ Ø§Ù„Ø£ÙˆØµØ§Ù â†’ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡
    DESCRIPTOR_MAPPING = {
        "ØµØ±Ø§Ù…Ø©": "Ù…Ù„Ø§Ø¨Ø³ Ø±Ø³Ù…ÙŠØ© Ù…Ø­Ø§ÙØ¸Ø© (Ø¨Ø¯Ù„Ø©/ØªØ§ÙŠÙˆØ±)",
        "ÙˆÙ‚Ø§Ø±": "Ø¨Ø¯Ù„Ø© Ø±Ø³Ù…ÙŠØ© ÙØ§Ø®Ø±Ø©",
        "Ø¹Ù…Ù„ÙŠØ© Ø¨Ø´Ø¯Ø©": "Ø³ØªØ§ÙŠÙ„ Ø¹Ù…Ù„ÙŠ Ø³Ø§Ø¯Ø© + Ø­Ø¯ Ø£Ø¯Ù†Ù‰ Ø¥ÙƒØ³Ø³ÙˆØ§Ø±Ø§Øª",
        "ÙˆØ³Ø§Ù…Ø©": "Ù‚Ù…ÙŠØµ Ø£Ù†ÙŠÙ‚ + Ø¬Ø§ÙƒÙŠØª Ø£Ùˆ Ø¨Ø¯Ù„Ø© ØºÙŠØ± Ø±Ø³Ù…ÙŠØ© (smart casual)",
        "Ø¬Ù…Ø§Ù„": "Ù…Ù„Ø§Ø¨Ø³ Ø£Ù†ÙŠÙ‚Ø© ØªØ¨Ø±Ø² Ø§Ù„Ù…Ø¸Ù‡Ø±",
        "Ø§Ø­Ø¨Ø§Ø·": "Ù…Ù„Ø§Ø¨Ø³ Ù…Ø±ØªØ¨Ø© Ù„ÙƒÙ† Ø¨Ø­Ø§Ù„Ø© Ù†ÙØ³ÙŠØ© ØªØ¸Ù‡Ø±",
        "Ù‚Ù„Ù‚": "Ù…Ù„Ø§Ø¨Ø³ Ø¹Ø§Ø¯ÙŠØ© Ù…Ø¹ ØªØ¹Ø¨ÙŠØ± Ø¬Ø³Ø¯ÙŠ Ù‚Ù„Ù‚",
        "Ù…Ø´Ù„ÙˆÙ„": "Ù…Ù„Ø§Ø¨Ø³ Ù…Ù†Ø²Ù„ÙŠØ© Ø±Ø§Ù‚ÙŠØ© / Ø±ÙˆØ¨ Ù…Ø±ÙŠØ­ (Ù„Ø§ ØªÙ‡Ù…Ù„ Ø§Ù„Ù…Ø¸Ù‡Ø±)",
    }
    
    # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø²Ù…Ø§Ù†ÙŠ/Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ
    TIME_LOCATION_RULES = {
        ("Ù„ÙŠÙ„", "Ù…Ù†Ø²Ù„"): "Ù…Ù„Ø§Ø¨Ø³ Ù…Ù†Ø²Ù„ÙŠØ© Ù„ÙŠÙ„ÙŠØ© / Ø¨ÙŠØ¬Ø§Ù…Ø© Ø±Ø§Ù‚ÙŠØ©",
        ("Ù„ÙŠÙ„", "ØºØ±ÙØ©"): "Ù…Ù„Ø§Ø¨Ø³ Ù…Ù†Ø²Ù„ÙŠØ© Ù„ÙŠÙ„ÙŠØ©",
        ("Ù†Ù‡Ø§Ø±", "Ù…ÙƒØªØ¨"): "Ø²ÙŠ Ø±Ø³Ù…ÙŠ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø¹Ù…Ù„",
        ("Ù†Ù‡Ø§Ø±", "Ù…Ø¨Ø§Ø­Ø«"): "Ø¨Ø¯Ù„Ø© Ø±Ø³Ù…ÙŠØ© + Ø³Ù„Ø§Ø­ Ø¬Ø§Ù†Ø¨ÙŠ",
        ("Ù†Ù‡Ø§Ø±", "Ù…Ø­Ø·Ø©"): "Ù…Ù„Ø§Ø¨Ø³ Ø¹Ù…Ù„ Ø±Ø³Ù…ÙŠØ© / smart casual",
        ("Ù†Ù‡Ø§Ø±", "ÙÙŠÙ„Ø§"): "Ù…Ù„Ø§Ø¨Ø³ Ø±Ø§Ù‚ÙŠØ© Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©",
        ("Ø®Ø§Ø±Ø¬ÙŠ", "Ù†Ù‡Ø§Ø±"): "Ù…Ù„Ø§Ø¨Ø³ ÙŠÙˆÙ…ÙŠØ© casual Ø£Ùˆ Ù†ØµÙ Ø±Ø³Ù…ÙŠØ©",
    }
    
    # Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ù‡Ù†Ø©
    PROFESSION_RULES = {
        "Ù…Ø¨Ø§Ø­Ø« Ø£Ù…Ù† Ø¯ÙˆÙ„Ø©": "Ø¨Ø¯Ù„Ø© Ø±Ø³Ù…ÙŠØ© Ø¯Ø§ÙƒÙ†Ø© + Ø³Ù„Ø§Ø­ Ø¬Ø§Ù†Ø¨ÙŠ (ØºÙŠØ± Ø¸Ø§Ù‡Ø±)",
        "Ù…Ù†ØªØ¬": "Ø¨Ø¯Ù„Ø© ÙØ§Ø®Ø±Ø© Ø£Ùˆ smart casual Ø±Ø§Ù‚ÙŠ",
        "Ù…Ù…Ø«Ù„Ø©": "Ø£Ø²ÙŠØ§Ø¡ Ø¹ØµØ±ÙŠØ© Ø£Ù†ÙŠÙ‚Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ø´Ù‡Ø¯",
        "Ø¥Ø¹Ù„Ø§Ù…ÙŠ Ø¯ÙŠÙ†ÙŠ": "Ù‚Ù…ÙŠØµ Ø±Ø³Ù…ÙŠ + Ø¬Ø§ÙƒÙŠØª Ø£Ùˆ Ø¨Ø¯Ù„Ø© Ù…Ø­Ø§ÙØ¸Ø©",
    }
    
    def infer_wardrobe(self, character: CharacterProfile, 
                      description: str, time: str, location: str) -> WardrobeSpec:
        """
        Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª
        
        Args:
            character: Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠØ©
            description: Ø§Ù„ÙˆØµÙ Ø§Ù„Ù†ØµÙŠ Ù…Ù† Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
            time: Ø§Ù„ÙˆÙ‚Øª (Ù„ÙŠÙ„/Ù†Ù‡Ø§Ø±)
            location: Ø§Ù„Ù…ÙˆÙ‚Ø¹
            
        Returns:
            Ù…ÙˆØ§ØµÙØ§Øª Ø§Ù„Ø²ÙŠ Ø§Ù„Ù…Ø³ØªÙ†ØªØ¬
        """
        wardrobe_elements = []
        
        # Level 1: Ù…Ù† Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø´Ø®ØµÙŠØ©
        desc_lower = description.lower()
        for descriptor, clothing in self.DESCRIPTOR_MAPPING.items():
            if descriptor in desc_lower:
                wardrobe_elements.append(clothing)
        
        # Level 2: Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø²Ù…Ø§Ù†ÙŠ/Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ
        location_type = self._extract_location_type(location)
        context_key = (time.lower(), location_type)
        
        if context_key in self.TIME_LOCATION_RULES:
            wardrobe_elements.append(self.TIME_LOCATION_RULES[context_key])
        
        # Level 3: Ù…Ù† Ø§Ù„Ù…Ù‡Ù†Ø©
        if character.profession and character.profession in self.PROFESSION_RULES:
            wardrobe_elements.append(
                self.PROFESSION_RULES[character.profession]
            )
        
        # Level 4: Ù…Ù† Ø§Ù„Ø·Ø¨Ù‚Ø© Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠØ©
        if character.social_class == "Ø¹Ù„ÙŠØ§" and "ÙÙŠÙ„Ø§" in location_type:
            wardrobe_elements.append("Ù…Ù„Ø§Ø¨Ø³ Ø±Ø§Ù‚ÙŠØ© ÙØ§Ø®Ø±Ø©")
        
        # Level 5: Ù…Ù† Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©
        if character.psychological_state:
            state = character.psychological_state.lower()
            if "Ù…Ø´Ù„ÙˆÙ„" in state or "Ù…Ø±ÙŠØ¶" in state:
                wardrobe_elements.append(
                    "Ù…Ù„Ø§Ø¨Ø³ Ù…Ù†Ø²Ù„ÙŠØ© Ø±Ø§Ù‚ÙŠØ© (Ø±ÙˆØ¨ Ø£Ùˆ Ø¨ÙŠØ¬Ø§Ù…Ø© ÙØ§Ø®Ø±Ø©)"
                )
        
        # Ø¯Ù…Ø¬ Ø§Ù„Ø¹Ù†Ø§ØµØ±
        if wardrobe_elements:
            description = self._merge_elements(wardrobe_elements)
        else:
            description = "Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚"
        
        return WardrobeSpec(
            character=character.full_name,
            description=description,
            is_inferred=True
        )
    
    def _extract_location_type(self, location: str) -> str:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ù† Ø§Ø³Ù…Ù‡"""
        location_lower = location.lower()
        
        type_mapping = {
            "Ù…Ù†Ø²Ù„": "Ù…Ù†Ø²Ù„",
            "Ø¨ÙŠØª": "Ù…Ù†Ø²Ù„",
            "Ø´Ù‚Ø©": "Ù…Ù†Ø²Ù„",
            "ØºØ±ÙØ©": "ØºØ±ÙØ©",
            "Ù…ÙƒØªØ¨": "Ù…ÙƒØªØ¨",
            "Ù…Ø­Ø·Ø©": "Ù…Ø­Ø·Ø©",
            "ÙÙŠÙ„Ø§": "ÙÙŠÙ„Ø§",
            "Ù…Ø¨Ø§Ø­Ø«": "Ù…Ø¨Ø§Ø­Ø«",
            "Ø³ÙŠØ§Ø±Ø©": "Ø³ÙŠØ§Ø±Ø©",
            "Ø´Ø§Ø±Ø¹": "Ø®Ø§Ø±Ø¬ÙŠ",
            "Ø·Ø±ÙŠÙ‚": "Ø®Ø§Ø±Ø¬ÙŠ",
        }
        
        for key, value in type_mapping.items():
            if key in location_lower:
                return value
        
        return "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
    
    def _merge_elements(self, elements: List[str]) -> str:
        """Ø¯Ù…Ø¬ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ Ø¨Ø°ÙƒØ§Ø¡"""
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        unique = []
        seen_concepts = set()
        
        for element in elements:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙÙ‡ÙˆÙ… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
            concept = element.split()[0].lower()
            if concept not in seen_concepts:
                unique.append(element)
                seen_concepts.add(concept)
        
        # Ø¯Ù…Ø¬
        if len(unique) == 1:
            return unique[0]
        else:
            return " | ".join(unique)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªÙ‚Ù†ÙŠØ© 4: Cinematic Pattern Recognition (ØªÙ…ÙŠÙŠØ² Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ÙŠØ©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CinematicAnalyzer:
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ÙŠØ© ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©
    """
    
    # Ø£Ù†Ù…Ø§Ø· Ø¥Ø®Ø±Ø§Ø¬ÙŠØ© Ø´Ø§Ø¦Ø¹Ø©
    PATTERNS = {
        'power_confrontation': {
            'triggers': [
                r'ÙŠØ¬Ù„Ø³.*Ø§Ù…Ø§Ù…',
                r'Ù…ÙƒØªØ¨.*(?:Ù…Ø¯ÙŠØ±|Ø±Ø¦ÙŠØ³|Ù…Ù†ØªØ¬)',
                r'Ø±Ø¬Ù„.*ÙŠØ¨Ø¯Ùˆ.*ÙˆÙ‚Ø§Ø±',
            ],
            'note': 'Ù…Ø´Ù‡Ø¯ Ù…ÙˆØ§Ø¬Ù‡Ø©: Ø¶Ø¨Ø· Ø¨Ù„ÙˆÙƒÙŠÙ†Ø¬ ÙŠØ¨Ø±Ø² ØµØ±Ø§Ø¹ Ø§Ù„Ø³Ù„Ø·Ø©.',
            'camera_note': 'Over-shoulder shots + ØªØ¨Ø§Ø¯Ù„ Ø²ÙˆØ§ÙŠØ§ Ù„Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙŠÙ†Ø§Ù…ÙŠÙƒÙŠØ©'
        },
        'discovery_moment': {
            'triggers': [
                r'(?:ÙŠØ¬Ø¯|ÙŠÙ„Ù…Ø­|ÙŠÙƒØªØ´Ù|ØªÙ‚Ø¹ Ø¹ÙŠÙ†ÙŠÙ‡)',
                r'Ø¸Ø±Ù|Ù…Ø³ØªÙ†Ø¯|ØµÙˆØ±Ø©',
                r'(?:Ø§Ø³ØªØºØ±Ø§Ø¨|Ù…ÙØ§Ø¬Ø£Ø©)',
            ],
            'note': 'Ù…Ø´Ù‡Ø¯ Ø§ÙƒØªØ´Ø§Ù: Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø±ÙŠØ£ÙƒØ´Ù† Ø§Ù„Ø´Ø®ØµÙŠØ© + Ù„Ù‚Ø·Ø© Ø¥Ø¯Ø±Ø§Ø¬ Ù„Ù„ÙƒØ§Ø¦Ù†.',
            'camera_note': 'Close-up Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙŠØ£ÙƒØ´Ù† + Insert shot Ù„Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ù…ÙƒØªØ´Ù'
        },
        'phone_conversation': {
            'triggers': [
                r'(?:Ù‡Ø§ØªÙ|Ù…ÙˆØ¨Ø§ÙŠÙ„|ØªÙ„ÙŠÙÙˆÙ†)',
                r'ÙŠØªØ­Ø¯Ø«\s+ÙÙŠ',
            ],
            'note': 'Ù…ÙƒØ§Ù„Ù…Ø© Ù‡Ø§ØªÙÙŠØ©: ØªØµÙˆÙŠØ± Ø¬Ø§Ù†Ø¨ ÙˆØ§Ø­Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.',
            'camera_note': 'Single-sided conversation - Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª'
        },
        'music_cue': {
            'triggers': [
                r'(?:ÙŠØºÙ†ÙŠ|ØµÙˆØª.*Ø¯ÙŠØ§Ø¨|ÙƒØ§Ø³ÙŠØª|Ù…ÙˆØ³ÙŠÙ‚Ù‰)',
                r'Ø£ØºÙ†ÙŠØ©|Ø§ØºÙ†ÙŠØ©',
            ],
            'note': 'Ù…ÙˆØ³ÙŠÙ‚Ù‰ ØªØµÙˆÙŠØ±ÙŠØ©: ØªØ£ÙƒÙŠØ¯ Ø­Ù‚ÙˆÙ‚ Ø§Ù„ØªØ´ØºÙŠÙ„ Ù‚Ø¨Ù„ Ø§Ù„ØªØµÙˆÙŠØ±.',
            'camera_note': 'Ø¯Ù…Ø¬ Ø§Ù„Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ù…Ø¹ Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø¨Ø³Ù„Ø§Ø³Ø©'
        },
        'vehicle_scene': {
            'triggers': [
                r'(?:Ø³ÙŠØ§Ø±Ø©|ÙŠÙ‚ÙˆØ¯)',
                r'(?:ÙŠØ¯Ø®Ù„|Ø¯Ø§Ø®Ù„).*Ø³ÙŠØ§Ø±Ø©',
            ],
            'note': 'Ù…Ø´Ù‡Ø¯ Ø³ÙŠØ§Ø±Ø©: Ø§Ø³ØªØ®Ø¯Ø§Ù… Process trailer Ø£Ùˆ Green screen Ø­Ø³Ø¨ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©.',
            'camera_note': 'Car mounting rigs + matching Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©'
        },
        'emotional_isolation': {
            'triggers': [
                r'(?:ÙˆØ­ÙŠØ¯|ÙˆØ­ÙŠØ¯Ø©|Ù…Ù†Ø¹Ø²Ù„)',
                r'(?:Ù‚Ù„Ù‚|Ø­Ø²Ù†|Ø§Ø­Ø¨Ø§Ø·).*Ø´Ø¯ÙŠØ¯',
                r'ÙŠÙÙƒØ±|ØªÙÙƒØ±',
            ],
            'note': 'Ù„Ø­Ø¸Ø© Ø¹Ø²Ù„Ø© Ø¹Ø§Ø·ÙÙŠØ©: Ø§Ø³ØªØ®Ø¯Ø§Ù… Wide shot Ù„Ù„ØªØ£ÙƒÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„ÙˆØ­Ø¯Ø©.',
            'camera_note': 'Wide angle + Ø¥Ø¶Ø§Ø¡Ø© mood Ù„Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ù†ÙØ³ÙŠØ©'
        },
        'rapid_search': {
            'triggers': [
                r'Ø¨Ø³Ø±Ø¹Ø©',
                r'ÙŠØ¨Ø­Ø«|ØªØ¨Ø­Ø«',
                r'Ù‚Ù„Ù‚|ØªÙˆØªØ±',
            ],
            'note': 'Ù…Ø´Ù‡Ø¯ Ø¨Ø­Ø«: Handheld camera Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„Ø¥Ø­Ø³Ø§Ø³ Ø¨Ø§Ù„ØªÙˆØªØ±.',
            'camera_note': 'Handheld + Quick cuts Ù„Ù„ØªØ¹Ø¨ÙŠØ± Ø¹Ù† Ø§Ù„Ø¹Ø¬Ù„Ø©'
        },
        'laptop_computer_action': {
            'triggers': [
                r'(?:Ù„Ø§Ø¨ØªÙˆØ¨|Ø­Ø§Ø³Ø¨)',
                r'(?:ÙŠÙØªØ­|ØªÙØªØ­|ÙŠÙ†Ø¸Ø±|ØªÙ†Ø¸Ø±)',
                r'Ø´Ø§Ø´Ø©|ØµÙˆØ±Ø©',
            ],
            'note': 'Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©: ØªØ·Ø§Ø¨Ù‚ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø´Ø§Ø´Ø© Ù…Ø¹ Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯.',
            'camera_note': 'Screen content playback + Over-shoulder shot'
        },
    }
    
    def analyze_scene(self, scene_text: str, scene_type: SceneType) -> Tuple[str, str]:
        """
        ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯ ÙˆØ§Ù‚ØªØ±Ø§Ø­ Ù…Ù„Ø§Ø­Ø¸Ø§Øª
        
        Returns:
            (production_note, camera_note)
        """
        text_lower = scene_text.lower()
        
        # ÙØ­Øµ ÙƒÙ„ Ù†Ù…Ø·
        for pattern_name, config in self.PATTERNS.items():
            matches = sum(
                1 for trigger in config['triggers']
                if re.search(trigger, text_lower)
            )
            
            # Ø¥Ø°Ø§ ØªØ·Ø§Ø¨Ù‚Øª Ù…Ø¹Ø¸Ù… Ø§Ù„Ù…Ø¤Ø´Ø±Ø§Øª
            if matches >= len(config['triggers']) - 1:
                return config['note'], config.get('camera_note', '')
        
        # Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯
        default_notes = {
            SceneType.DIALOGUE_HEAVY: (
                "Ù…Ø´Ù‡Ø¯ Ø­ÙˆØ§Ø±ÙŠ: Ø§Ù„ØªØ±ÙƒÙŠØ² Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªÙØ§Ø¹Ù„.",
                "Shot-reverse-shot + Medium shots Ù„Ù„Ø­ÙˆØ§Ø±"
            ),
            SceneType.ACTION_SEQUENCE: (
                "Ù…Ø´Ù‡Ø¯ Ø­Ø±ÙƒÙŠ: ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø­Ø±ÙƒØ© ÙˆØ§Ù„Ù€ blocking.",
                "Dynamic camera movement + multiple angles"
            ),
            SceneType.CONFRONTATION: (
                "Ù…Ø´Ù‡Ø¯ ØµØ±Ø§Ø¹: ØªØµØ¹ÙŠØ¯ ØªØ¯Ø±ÙŠØ¬ÙŠ ÙÙŠ Ø§Ù„Ø¥ÙŠÙ‚Ø§Ø¹.",
                "Tightening shots + Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙˆØªØ± Ø§Ù„Ø¨ØµØ±ÙŠ"
            ),
        }
        
        return default_notes.get(
            scene_type,
            ("Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø±Ø§ÙƒÙˆØ±Ø§Øª (Continuity)", "")
        )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªÙ‚Ù†ÙŠØ© 5: Scene Relationship Graph (Ø´Ø¨ÙƒØ© Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SceneContextGraph:
    """
    Ø¨Ù†Ø§Ø¡ Ø´Ø¨ÙƒØ© Ø¹Ù„Ø§Ù‚Ø§Øª Ø°ÙƒÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯
    ØªØªØ¨Ø¹ Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©: Ø§Ù„Ù…Ù„Ø§Ø¨Ø³ØŒ Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù…ØŒ Ø§Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„Ù†ÙØ³ÙŠØ©
    """
    
    def __init__(self):
        # Ø³Ø¬Ù„Ø§Øª Ø§Ù„ØªØªØ¨Ø¹
        self.character_timeline: Dict[str, List[Dict]] = defaultdict(list)
        self.prop_registry: Dict[str, List[str]] = defaultdict(list)
        self.location_history: Dict[str, List[str]] = defaultdict(list)
        
        # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
        self.continuity_map: Dict[str, str] = {}
    
    def register_scene(self, scene: DetailedBreakdown):
        """ØªØ³Ø¬ÙŠÙ„ Ù…Ø´Ù‡Ø¯ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©"""
        scene_id = scene.scene_number
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª
        for char in scene.cast:
            self.character_timeline[char].append({
                'scene': scene_id,
                'time': scene.day_night,
                'location': scene.location,
                'wardrobe': scene.costumes_html,
            })
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù…
        for prop in scene.props_list:
            self.prop_registry[prop].append(scene_id)
        
        # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…ÙˆÙ‚Ø¹
        self.location_history[scene.location].append(scene_id)
    
    def detect_continuation(self, current_scene: DetailedBreakdown) -> Optional[str]:
        """
        ÙƒØ´Ù Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø§Ø³ØªÙ…Ø±Ø§Ø±Ø§Ù‹ Ù„Ù…Ø´Ù‡Ø¯ Ø³Ø§Ø¨Ù‚
        
        Returns:
            Ø±Ù‚Ù… Ø§Ù„Ù…Ø´Ù‡Ø¯ Ø§Ù„Ø³Ø§Ø¨Ù‚ Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯ Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
        """
        # ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙØ³ Ø§Ù„Ù…ÙˆÙ‚Ø¹ + Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª + Ø´Ø®ØµÙŠØ§Øª Ù…Ø´ØªØ±ÙƒØ©
        location = current_scene.location
        time = current_scene.day_night
        current_chars = set(current_scene.cast)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¢Ø®Ø± 3 Ù…Ø´Ø§Ù‡Ø¯
        recent_scenes = []
        for char in current_chars:
            if char in self.character_timeline:
                recent_scenes.extend(self.character_timeline[char][-3:])
        
        for entry in reversed(recent_scenes):
            if (entry['location'] == location and 
                entry['time'] == time):
                return entry['scene']
        
        return None
    
    def get_continuity_notes(self, scene: DetailedBreakdown) -> List[str]:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©"""
        notes = []
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù… Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©
        for prop in scene.props_list:
            if len(self.prop_registry[prop]) > 1:
                notes.append(
                    f"Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©: ØªØ·Ø§Ø¨Ù‚ {prop} Ù…Ø¹ Ø¸Ù‡ÙˆØ±Ù‡ ÙÙŠ "
                    f"Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ {', '.join(self.prop_registry[prop][:-1])}"
                )
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø´Ø®ØµÙŠØ§Øª ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…ÙˆÙ‚Ø¹
        location_chars = []
        for char in scene.cast:
            if char in self.character_timeline:
                prev_entry = self.character_timeline[char][-2] \
                    if len(self.character_timeline[char]) > 1 else None
                
                if prev_entry and prev_entry['location'] == scene.location:
                    location_chars.append(char)
        
        if location_chars:
            notes.append(
                f"Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø£Ø²ÙŠØ§Ø¡: {', '.join(location_chars)} "
                f"ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…ÙˆÙ‚Ø¹"
            )
        
        return notes


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªÙ‚Ù†ÙŠØ© 6: Legal Alert System (Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class LegalAlertSystem:
    """ÙƒØ´Ù ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
    
    def scan_for_alerts(self, text: str) -> List[LegalAlert]:
        """ÙØ­Øµ Ø§Ù„Ù†Øµ Ù„Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©"""
        alerts = []
        text_lower = text.lower()
        
        # ÙØ­Øµ Ø§Ù„Ù…Ø´Ø§Ù‡ÙŠØ±
        for celebrity in KnowledgeBase.CELEBRITY_NAMES:
            if celebrity.lower() in text_lower:
                alerts.append(LegalAlert(
                    alert_type="celebrity",
                    entity_name=celebrity,
                    description=f'Ø°ÙƒØ± Ø§Ø³Ù… "{celebrity}" - ÙŠØªØ·Ù„Ø¨ Ù…Ø±Ø§Ø¬Ø¹Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©',
                    severity="warning"
                ))
        
        # ÙØ­Øµ Ø§Ù„Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ¬Ø§Ø±ÙŠØ©
        for brand in KnowledgeBase.BRAND_NAMES:
            if brand.lower() in text_lower:
                alerts.append(LegalAlert(
                    alert_type="brand",
                    entity_name=brand,
                    description=f'Ø°ÙƒØ± Ø¹Ù„Ø§Ù…Ø© ØªØ¬Ø§Ø±ÙŠØ© "{brand}" - Ù…Ø±Ø§Ø¬Ø¹Ø© Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…',
                    severity="warning"
                ))
        
        # ÙØ­Øµ Ø§Ù„Ø£ØºØ§Ù†ÙŠ
        for song in KnowledgeBase.SONG_TITLES:
            if song.lower() in text_lower:
                alerts.append(LegalAlert(
                    alert_type="music",
                    entity_name=song,
                    description=f'ØªØ´ØºÙŠÙ„ Ø£ØºÙ†ÙŠØ© "{song}" - Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ù‚ÙˆÙ‚ Ø§Ù„ØªØ´ØºÙŠÙ„',
                    severity="critical"
                ))
        
        # ÙØ­Øµ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ³ÙŠÙ‚Ù‰ Ø¹Ø§Ù…Ø©
        music_keywords = ['ÙŠØºÙ†ÙŠ', 'Ø£ØºÙ†ÙŠØ©', 'Ø§ØºÙ†ÙŠØ©', 'Ù…ÙˆØ³ÙŠÙ‚Ù‰', 'ÙƒØ§Ø³ÙŠØª']
        if any(kw in text_lower for kw in music_keywords):
            if not any(alert.alert_type == "music" for alert in alerts):
                alerts.append(LegalAlert(
                    alert_type="music",
                    entity_name="Ù…Ø­ØªÙˆÙ‰ Ù…ÙˆØ³ÙŠÙ‚ÙŠ",
                    description="Ù…Ø­ØªÙˆÙ‰ Ù…ÙˆØ³ÙŠÙ‚ÙŠ - Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø­Ù‚ÙˆÙ‚ Ø§Ù„ØªØ´ØºÙŠÙ„",
                    severity="warning"
                ))
        
        return alerts


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ù…Ø­Ù„Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ø§Ù„Ù…ØªØ·ÙˆØ± (Revolutionary Parser)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RevolutionarySceneParser:
    """
    Ù…Ø­Ù„Ù„ Ù…ØªÙ‚Ø¯Ù… ÙŠØ¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø«ÙˆØ±ÙŠØ©
    Multi-Pass Architecture
    """
    
    def __init__(self):
        logger.info("â•" * 70)
        logger.info("ØªÙ‡ÙŠØ¦Ø© Ù†Ø¸Ø§Ù… Breakdown Ø§Ù„Ø«ÙˆØ±ÙŠ...")
        logger.info("â•" * 70)
        
        # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
        self.synopsis_gen = SynopsisGenerator()
        self.prop_classifier = PropClassifier()
        self.wardrobe_engine = WardrobeInferenceEngine()
        self.cinematic_analyzer = CinematicAnalyzer()
        self.context_graph = SceneContextGraph()
        self.legal_system = LegalAlertSystem()
        
        logger.info("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ SynopsisGenerator")
        logger.info("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ PropClassifier")
        logger.info("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ WardrobeInferenceEngine")
        logger.info("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ CinematicAnalyzer")
        logger.info("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ SceneContextGraph")
        logger.info("âœ“ ØªÙ… ØªØ­Ù…ÙŠÙ„ LegalAlertSystem")
        logger.info("â•" * 70)
    
    async def analyze_scene(self, scene_text: str, scene_number: str) -> DetailedBreakdown:
        """
        ØªØ­Ù„ÙŠÙ„ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ (Multi-Pass)
        
        Pass 1: Raw Extraction
        Pass 2: Intelligent Enrichment
        Pass 3: Refinement & Validation
        """
        logger.info(f"ğŸ” ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯ {scene_number}...")
        
        # â•â•â• Pass 1: Raw Extraction â•â•â•
        breakdown = await self._pass1_extract(scene_text, scene_number)
        
        # â•â•â• Pass 2: Intelligent Enrichment â•â•â•
        await self._pass2_enrich(breakdown, scene_text)
        
        # â•â•â• Pass 3: Refinement & Validation â•â•â•
        await self._pass3_refine(breakdown)
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø§Ù„Ø´Ø¨ÙƒØ©
        self.context_graph.register_scene(breakdown)
        
        logger.info(f"âœ“ ØªÙ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯ {scene_number}")
        return breakdown
    
    async def _pass1_extract(self, text: str, scene_num: str) -> DetailedBreakdown:
        """Pass 1: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£ÙˆÙ„ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        lines = [l.rstrip() for l in text.splitlines() if l.strip()]
        header = lines[0] if lines else ""
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù€ header
        int_ext, day_night, location = self._parse_header(header, text)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª
        cast = self._extract_cast(text)
        
        # ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯
        scene_type = self._classify_scene_type(text, cast)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒØ§Ø¦Ù† Ø§Ù„Ø£ÙˆÙ„ÙŠ
        breakdown = DetailedBreakdown(
            scene_number=scene_num,
            int_ext=int_ext,
            day_night=day_night,
            location=location,
            scene_type=scene_type,
            original_text=text,
            cast=cast
        )
        
        return breakdown
    
    async def _pass2_enrich(self, breakdown: DetailedBreakdown, text: str):
        """Pass 2: Ø¥Ø«Ø±Ø§Ø¡ Ø°ÙƒÙŠ"""
        
        # 1. ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø¯Ù„Ø§Ù„ÙŠ
        breakdown.summary = self.synopsis_gen.generate_synopsis(
            text,
            breakdown.scene_type,
            breakdown.cast
        )
        
        # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù…
        await self._extract_and_classify_props(breakdown, text)
        
        # 3. Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡
        await self._infer_wardrobes(breakdown, text)
        
        # 4. ØªØ­Ù„ÙŠÙ„ Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠ
        production_note, camera_note = self.cinematic_analyzer.analyze_scene(
            text,
            breakdown.scene_type
        )
        breakdown.cinematic_notes = production_note
        breakdown.camera_lighting = camera_note if camera_note else \
            self._generate_camera_lighting(breakdown)
        
        # 5. ÙƒØ´Ù Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
        breakdown.legal_alerts = self.legal_system.scan_for_alerts(text)
        
        # 6. ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯
        await self._rule_based_enrichment(breakdown, text)
    
    async def _pass3_refine(self, breakdown: DetailedBreakdown):
        """Pass 3: ØªÙ†Ù‚ÙŠØ­ ÙˆØªØ¯Ù‚ÙŠÙ‚"""
        
        # ÙƒØ´Ù Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
        prev_scene = self.context_graph.detect_continuation(breakdown)
        if prev_scene:
            breakdown.is_continuation = True
            breakdown.previous_scene_ref = prev_scene
        
        # Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ©
        continuity_notes = self.context_graph.get_continuity_notes(breakdown)
        breakdown.continuity_notes.extend(continuity_notes)
        
        # Ø¨Ù†Ø§Ø¡ HTML Ù„Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
        await self._build_html_fields(breakdown)
        
        # ØªØ¯Ù‚ÙŠÙ‚ Ù†Ù‡Ø§Ø¦ÙŠ
        await self._final_validation(breakdown)
    
    def _parse_header(self, header: str, fallback_text: str) -> Tuple[str, str, str]:
        """ØªØ­Ù„ÙŠÙ„ header Ø§Ù„Ù…Ø´Ù‡Ø¯"""
        h = re.sub(r'\s+', ' ', header.strip())
        
        # Ø§ÙØªØ±Ø§Ø¶Ø§Øª Ø£ÙˆÙ„ÙŠØ©
        int_ext = "Ø¯Ø§Ø®Ù„ÙŠ (INT)"
        day_night = "Ù†Ù‡Ø§Ø±"
        location = "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        
        # ÙƒØ´Ù INT/EXT
        low = h.lower()
        if re.search(r'\b(Ø®Ø§Ø±Ø¬ÙŠ|ext\.?)\b', low) and not re.search(r'\b(Ø¯Ø§Ø®Ù„ÙŠ|int\.?)\b', low):
            int_ext = "Ø®Ø§Ø±Ø¬ÙŠ (EXT)"
        elif re.search(r'\b(Ø¯Ø§Ø®Ù„ÙŠ|int\.?)\b', low):
            int_ext = "Ø¯Ø§Ø®Ù„ÙŠ (INT)"
        
        # ÙƒØ´Ù Day/Night
        if re.search(r'\b(Ù„ÙŠÙ„|night)\b', low):
            day_night = "Ù„ÙŠÙ„"
        elif re.search(r'\b(Ù†Ù‡Ø§Ø±|day)\b', low):
            day_night = "Ù†Ù‡Ø§Ø±"
        else:
            # Fallback Ù…Ù† Ø§Ù„Ù†Øµ
            if re.search(r'\b(Ù„ÙŠÙ„|night)\b', fallback_text.lower()):
                day_night = "Ù„ÙŠÙ„"
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙˆÙ‚Ø¹
        temp = re.sub(r'^(Ù…Ø´Ù‡Ø¯|scene)\s*\d+\s*[:\-â€“â€”]?\s*', '', h, flags=re.I).strip()
        parts = [p.strip() for p in re.split(r'[-â€“â€”|]+', temp) if p.strip()]
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªØµÙ†ÙŠÙÙŠØ©
        filtered = []
        for p in parts:
            pl = p.lower()
            if re.fullmatch(r'(Ø¯Ø§Ø®Ù„ÙŠ|int\.?|Ø®Ø§Ø±Ø¬ÙŠ|ext\.?|Ù†Ù‡Ø§Ø±|day|Ù„ÙŠÙ„|night)', pl):
                continue
            filtered.append(p)
        
        if filtered:
            location = re.sub(r'\s+', ' ', ' - '.join(filtered))
        else:
            loc = re.sub(
                r'(Ù…Ø´Ù‡Ø¯|scene|\d+|Ø¯Ø§Ø®Ù„ÙŠ|Ø®Ø§Ø±Ø¬ÙŠ|int|ext|Ù„ÙŠÙ„|Ù†Ù‡Ø§Ø±|day|night|[:\-â€“â€”])',
                ' ',
                h,
                flags=re.I
            )
            loc = re.sub(r'\s+', ' ', loc.strip())
            location = loc if loc else "ØºÙŠØ± Ù…Ø­Ø¯Ø¯"
        
        return int_ext, day_night, location
    
    def _extract_cast(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ù…Ù† Ø§Ù„Ø­ÙˆØ§Ø±"""
        pattern = re.compile(r'^\s*([A-Za-z\u0600-\u06FF][A-Za-z\u0600-\u06FF\s]{1,40}):', re.M)
        matches = pattern.findall(text)
        
        cast = []
        for m in matches:
            name = re.sub(r'\s+', ' ', m.strip())
            
            # ÙÙ„ØªØ±Ø©
            if len(name) < 2 or len(name.split()) > 4:
                continue
            if name.lower() in {"Ù…Ø´Ù‡Ø¯", "scene"}:
                continue
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø§Ø³Ù…
            normalized = self._normalize_character_name(name)
            if normalized and normalized not in cast:
                cast.append(normalized)
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¥Ø¶Ø§ÙÙŠ Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ÙˆØµÙÙŠ
        cast.extend(self._extract_cast_from_description(text))
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        return list(dict.fromkeys(cast))
    
    def _normalize_character_name(self, name: str) -> str:
        """ØªØ·Ø¨ÙŠØ¹ Ø§Ø³Ù… Ø§Ù„Ø´Ø®ØµÙŠØ© Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ù…Ù„"""
        name_clean = name.strip()
        
        # Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        for key, profile in KnowledgeBase.KNOWN_CHARACTERS.items():
            if key.lower() == name_clean.lower():
                return profile.full_name
        
        return name_clean
    
    def _extract_cast_from_description(self, text: str) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø´Ø®ØµÙŠØ§Øª Ù…Ù† Ø§Ù„ÙˆØµÙ Ø§Ù„Ø³Ø±Ø¯ÙŠ"""
        cast = []
        
        # Ø£Ù†Ù…Ø§Ø· Ø´Ø§Ø¦Ø¹Ø©
        patterns = [
            r'ØªØ®Ø±Ø¬\s+([A-Za-z\u0600-\u06FF]+)\s+(?:Ø³Ù…Ø§Ø­Ø©)?',
            r'ÙŠØ¬Ù„Ø³\s+([A-Za-z\u0600-\u06FF]+)\s+',
            r'ÙŠØ¯Ø®Ù„\s+([A-Za-z\u0600-\u06FF]+)\s+',
            r'ØªØ¬Ù„Ø³\s+([A-Za-z\u0600-\u06FF]+)\s+',
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                normalized = self._normalize_character_name(match)
                if normalized and normalized not in cast:
                    cast.append(normalized)
        
        return cast
    
    def _classify_scene_type(self, text: str, cast: List[str]) -> SceneType:
        """ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯"""
        text_lower = text.lower()
        
        # Ù†Ø³Ø¨Ø© Ø§Ù„Ø­ÙˆØ§Ø±
        dialogue_lines = len(re.findall(r'^\s*[^:\n]{1,40}:', text, re.M))
        total_lines = len(text.split('\n'))
        dialogue_ratio = dialogue_lines / max(total_lines, 1)
        
        # ØªØµÙ†ÙŠÙ
        if dialogue_ratio > 0.4:
            # Ù…Ø´Ù‡Ø¯ Ø­ÙˆØ§Ø±ÙŠ
            if any(word in text_lower for word in ['Ù…ÙˆØ§Ø¬Ù‡Ø©', 'ØµØ±Ø§Ø¹', 'Ø®Ù„Ø§Ù', 'Ø¬Ø¯Ø§Ù„']):
                return SceneType.CONFRONTATION
            return SceneType.DIALOGUE_HEAVY
        
        # Ø£ÙØ¹Ø§Ù„ Ø§ÙƒØªØ´Ø§Ù
        if any(verb in text_lower for verb in ['ÙŠØ¬Ø¯', 'ÙŠÙ„Ù…Ø­', 'ÙŠÙƒØªØ´Ù', 'ØªÙ‚Ø¹ Ø¹ÙŠÙ†Ù‡']):
            return SceneType.DISCOVERY
        
        # Ø£ÙØ¹Ø§Ù„ Ø­Ø±ÙƒÙŠØ©
        action_verbs = ['ÙŠØ¯Ø®Ù„', 'ÙŠØ®Ø±Ø¬', 'ÙŠØ¬Ø±ÙŠ', 'ÙŠÙ‚ÙØ²', 'ÙŠÙ‚ÙˆØ¯', 'ÙŠØ¶Ø±Ø¨']
        if sum(1 for v in action_verbs if v in text_lower) >= 2:
            return SceneType.ACTION_SEQUENCE
        
        # Ø­Ø§Ù„Ø§Øª Ø¹Ø§Ø·ÙÙŠØ©
        if any(word in text_lower for word in ['Ù‚Ù„Ù‚', 'Ø­Ø²Ù†', 'Ø§Ø­Ø¨Ø§Ø·', 'Ø³Ø¹Ø§Ø¯Ø©', 'ÙØ±Ø­']):
            return SceneType.EMOTIONAL
        
        return SceneType.TRANSITION
    
    async def _extract_and_classify_props(self, breakdown: DetailedBreakdown, text: str):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù…"""
        text_lower = text.lower()
        
        # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù… Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©
        prop_candidates = []
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ù„Ù€ patterns
        prop_patterns = {
            'Ø¸Ø±Ù': r'Ø¸Ø±Ù|Ù…Ø¸Ø±ÙˆÙ',
            'Ù‡Ø§ØªÙ Ù…Ø­Ù…ÙˆÙ„': r'Ù‡Ø§ØªÙ|Ù…ÙˆØ¨Ø§ÙŠÙ„|ØªÙ„ÙŠÙÙˆÙ†(?!\s+Ø¢Ù„ÙŠ)',
            'Ø­Ø§Ø³Ø¨ Ø¢Ù„ÙŠ': r'Ù„Ø§Ø¨ØªÙˆØ¨|Ø­Ø§Ø³Ø¨\s*(?:Ø¢Ù„ÙŠ|Ø§Ù„ÙŠ)|ÙƒÙ…Ø¨ÙŠÙˆØªØ±',
            'Ù…Ø¬Ù„Ø§Øª': r'Ù…Ø¬Ù„Ø©|Ù…Ø¬Ù„Ø§Øª',
            'Ø­Ù‚ÙŠØ¨Ø©': r'Ø­Ù‚ÙŠØ¨Ø©|Ø´Ù†Ø·Ø©',
            'ÙƒØ§Ø³ÙŠØª': r'ÙƒØ§Ø³ÙŠØª|Ø±Ø§Ø¯ÙŠÙˆ',
            'ÙƒØ±Ø³ÙŠ Ù…ØªØ­Ø±Ùƒ': r'ÙƒØ±Ø³ÙŠ\s+Ù…ØªØ­Ø±Ùƒ',
            'ØµÙˆØ±Ø©': r'ØµÙˆØ±Ø©|ØµÙˆØ±',
        }
        
        for prop_name, pattern in prop_patterns.items():
            if re.search(pattern, text_lower):
                # ØªØµÙ†ÙŠÙ Ø§Ù„Ø¯Ø¹Ù…Ø©
                category, enhanced_name = self.prop_classifier.classify_prop(
                    prop_name,
                    text_lower
                )
                
                if category == 'props':
                    prop_candidates.append(enhanced_name)
                elif category == 'vehicles':
                    if breakdown.vehicles == "Ù„Ø§ ÙŠÙˆØ¬Ø¯":
                        breakdown.vehicles = enhanced_name
                    else:
                        breakdown.vehicles += f"ØŒ {enhanced_name}"
                # set_dressing ÙŠÙØ¹Ø§Ù„Ø¬ ÙÙŠ _rule_based_enrichment
        
        # Ø­ÙØ¸ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
        breakdown.props_list = prop_candidates
    
    async def _infer_wardrobes(self, breakdown: DetailedBreakdown, text: str):
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ Ù„ÙƒÙ„ Ø´Ø®ØµÙŠØ©"""
        wardrobe_specs = []
        
        for char_name in breakdown.cast:
            # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø´Ø®ØµÙŠ
            profile = None
            for key, p in KnowledgeBase.KNOWN_CHARACTERS.items():
                if p.full_name == char_name:
                    profile = p
                    break
            
            if not profile:
                profile = CharacterProfile(
                    name=char_name,
                    full_name=char_name
                )
            
            # Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø²ÙŠ
            spec = self.wardrobe_engine.infer_wardrobe(
                profile,
                text,
                breakdown.day_night,
                breakdown.location
            )
            
            wardrobe_specs.append(spec)
            breakdown.cast_profiles[char_name] = profile
        
        breakdown.wardrobe_specs = wardrobe_specs
    
    async def _rule_based_enrichment(self, breakdown: DetailedBreakdown, text: str):
        """Ø¥Ø«Ø±Ø§Ø¡ Ù‚Ø§Ø¦Ù… Ø¹Ù„Ù‰ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯"""
        text_lower = text.lower()
        
        # Extras
        if re.search(r'(Ø¬Ù…Ù‡ÙˆØ±|Ø­Ø´Ø¯|Ø²Ø­Ø§Ù…|Ù…Ø§Ø±Ø©|Ù†Ø§Ø³ ÙƒØªÙŠØ±)', text_lower):
            breakdown.extras_html = 'ÙŠÙ„Ø²Ù… Ù…Ù…Ø«Ù„ÙˆÙ† Ø¥Ø¶Ø§ÙÙŠÙˆÙ† (Ø¬Ù…Ù‡ÙˆØ±/Ø­Ø´Ø¯) <span class="tag">ØªÙ‚Ø¯ÙŠØ±: 10-20 Ø´Ø®Øµ</span>'
        else:
            breakdown.extras_html = '<span class="muted">ØºÙŠØ± Ù…Ø°ÙƒÙˆØ± (Ù„Ø§ ÙŠÙ„Ø²Ù…)</span>'
        
        # Set Dressing
        set_elements = []
        
        dressing_patterns = {
            'Ù…Ø±Ø¢Ø©': r'Ù…Ø±Ø¢Ø©|Ù…Ø±Ø§ÙŠØ©',
            'ÙƒØ±Ø³ÙŠ': r'ÙƒØ±Ø³ÙŠ(?!\s+Ù…ØªØ­Ø±Ùƒ)',
            'Ø·Ø§ÙˆÙ„Ø©': r'Ø·Ø§ÙˆÙ„Ø©|Ù…Ù†Ø¶Ø¯Ø©',
            'Ø³Ø±ÙŠØ±': r'Ø³Ø±ÙŠØ±',
            'Ø®Ø²Ø§Ù†Ø©': r'Ø®Ø²Ø§Ù†Ø©|Ø¯ÙˆÙ„Ø§Ø¨',
        }
        
        for element, pattern in dressing_patterns.items():
            if re.search(pattern, text_lower):
                set_elements.append(element)
        
        # Ø¥Ø¶Ø§ÙØ© ØªÙØ§ØµÙŠÙ„ Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆÙ‚Ø¹
        location_lower = breakdown.location.lower()
        
        if 'Ù…ÙƒØªØ¨' in location_lower:
            set_elements.extend(['Ù…ÙƒØªØ¨ Ù…Ø¯ÙŠØ±', 'ÙƒØ±Ø§Ø³ÙŠ', 'Ø£Ø±ÙÙ'])
        elif 'ØºØ±ÙØ© Ù…ÙƒÙŠØ§Ø¬' in location_lower:
            set_elements.extend(['Ù…Ø±Ø¢Ø© Ø¨Ø¥Ø¶Ø§Ø¡Ø©', 'ÙƒØ±Ø³ÙŠ Ù…ÙƒÙŠØ§Ø¬', 'Ø·Ø§ÙˆÙ„Ø© Ø£Ø¯ÙˆØ§Øª'])
        elif 'Ù…Ù†Ø²Ù„' in location_lower or 'ØºØ±ÙØ©' in location_lower:
            if 'Ù†ÙˆÙ…' in location_lower:
                set_elements.extend(['Ø³Ø±ÙŠØ±', 'Ø®Ø²Ø§Ù†Ø©', 'Ø¥Ø¶Ø§Ø¡Ø© Ø¬Ø§Ù†Ø¨ÙŠØ©'])
            else:
                set_elements.extend(['Ø£Ø«Ø§Ø« Ù…Ù†Ø²Ù„ÙŠ'])
        elif 'ÙÙŠÙ„Ø§' in location_lower:
            set_elements.extend(['Ø£Ø«Ø§Ø« Ø±Ø§Ù‚Ù', 'Ø¯ÙŠÙƒÙˆØ± ÙØ§Ø®Ø±'])
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
        set_elements = list(dict.fromkeys(set_elements))
        
        if set_elements:
            breakdown.set_dressing_html = ', '.join(set_elements) + \
                ' <span class="tag">Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚</span>'
        else:
            breakdown.set_dressing_html = 'Ø­Ø³Ø¨ Ø§Ù„Ù…ÙˆÙ‚Ø¹ <span class="tag">Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚</span>'
        
        # Special Effects
        effects = []
        
        if re.search(r'(Ø§Ù†ÙØ¬Ø§Ø±|Ø¯Ø®Ø§Ù†|Ù†Ø§Ø±|ØªÙØ¬ÙŠØ±)', text_lower):
            effects.append('Ù…Ø¤Ø«Ø±Ø§Øª Ø¹Ù…Ù„ÙŠØ© (Ø§Ù†ÙØ¬Ø§Ø±/Ø¯Ø®Ø§Ù†)')
        
        if re.search(r'(Ù…Ø·Ø±|Ø«Ù„Ø¬|Ø±ÙŠØ§Ø­)', text_lower):
            effects.append('Ù…Ø¤Ø«Ø±Ø§Øª Ø·Ù‚Ø³')
        
        if re.search(r'(ØµÙˆØ±Ø©.*Ø³Ø·Ø­.*Ù…ÙƒØªØ¨|Ø´Ø§Ø´Ø©.*Ø­Ø§Ø³Ø¨|playback)', text_lower):
            effects.append('ØªØºÙŠÙŠØ± Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø´Ø§Ø´Ø© (Playback)')
        
        if effects:
            breakdown.special_effects_html = '<br>'.join(effects)
        else:
            breakdown.special_effects_html = 'Ù„Ø§ ÙŠÙˆØ¬Ø¯'
        
        # Sound
        sound_elements = []
        
        if re.search(r'(Ø­ÙˆØ§Ø±|ÙŠØªØ­Ø¯Ø«|ØªØªØ­Ø¯Ø«|ÙŠÙ‚ÙˆÙ„|ØªÙ‚ÙˆÙ„)', text_lower):
            sound_elements.append('Ø­ÙˆØ§Ø± Ù…Ø¨Ø§Ø´Ø±')
        
        if re.search(r'(ÙŠØºÙ†ÙŠ|Ù…ÙˆØ³ÙŠÙ‚Ù‰|Ø£ØºÙ†ÙŠØ©|ÙƒØ§Ø³ÙŠØª)', text_lower):
            sound_elements.append('Ù…ÙˆØ³ÙŠÙ‚Ù‰ ØªØµÙˆÙŠØ±ÙŠØ©')
        
        if re.search(r'(ÙŠØ·Ø±Ù‚|Ø·Ø±Ù‚.*Ø¨Ø§Ø¨|knock)', text_lower):
            sound_elements.append('Ø·Ø±Ù‚ Ø¨Ø§Ø¨')
        
        if re.search(r'(ØµÙˆØª.*Ø³ÙŠØ§Ø±Ø©|Ù…Ø­Ø±Ùƒ)', text_lower):
            sound_elements.append('Ø£ØµÙˆØ§Øª Ù…Ø±ÙƒØ¨Ø§Øª')
        
        breakdown.sound_html = ' + '.join(sound_elements) if sound_elements \
            else 'Ø­ÙˆØ§Ø± Ù…Ø¨Ø§Ø´Ø±'
        
        # Makeup (Ø§ÙØªØ±Ø§Ø¶ÙŠ)
        makeup_items = []
        for char in breakdown.cast:
            makeup_items.append(
                f'â€¢ {char}: ØªØµØ­ÙŠØ­ ÙƒØ§Ù…ÙŠØ±Ø§ Ø§Ø¹ØªÙŠØ§Ø¯ÙŠ'
            )
        
        if makeup_items:
            breakdown.makeup_html = '<br>'.join(makeup_items) + \
                ' <span class="tag">Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚</span>'
        else:
            breakdown.makeup_html = 'ØªØµØ­ÙŠØ­ ÙƒØ§Ù…ÙŠØ±Ø§ <span class="tag">Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚</span>'
    
    def _generate_camera_lighting(self, breakdown: DetailedBreakdown) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„ØªØµÙˆÙŠØ± ÙˆØ§Ù„Ø¥Ø¶Ø§Ø¡Ø©"""
        time = breakdown.day_night
        int_ext = breakdown.int_ext
        
        if "Ø¯Ø§Ø®Ù„ÙŠ" in int_ext:
            if time == "Ù„ÙŠÙ„":
                return "Ù„ÙŠÙ„ Ø¯Ø§Ø®Ù„ÙŠ"
            else:
                return "Ù†Ù‡Ø§Ø± Ø¯Ø§Ø®Ù„ÙŠ"
        else:
            if time == "Ù„ÙŠÙ„":
                return "Ù„ÙŠÙ„ Ø®Ø§Ø±Ø¬ÙŠ"
            else:
                return "Ù†Ù‡Ø§Ø± Ø®Ø§Ø±Ø¬ÙŠ"
    
    async def _build_html_fields(self, breakdown: DetailedBreakdown):
        """Ø¨Ù†Ø§Ø¡ Ø­Ù‚ÙˆÙ„ HTML Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©"""
        
        # Costumes HTML
        if breakdown.wardrobe_specs:
            costume_items = []
            for spec in breakdown.wardrobe_specs:
                item = f'â€¢ {spec.character}: {spec.description}'
                costume_items.append(item)
            
            breakdown.costumes_html = '<br>'.join(costume_items) + \
                ' <span class="tag">Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚</span>'
        else:
            breakdown.costumes_html = 'Ø­Ø³Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚ <span class="tag">Ù…Ø³ØªÙ†ØªØ¬ Ù…Ù† Ø§Ù„Ø³ÙŠØ§Ù‚</span>'
        
        # Props HTML
        if breakdown.props_list:
            if len(breakdown.props_list) == 1:
                breakdown.props_html = breakdown.props_list[0]
            else:
                props_li = ''.join([f'<li>{p}</li>' for p in breakdown.props_list])
                breakdown.props_html = f'<ul class="bullets">{props_li}</ul>'
        else:
            breakdown.props_html = 'Ù„Ø§ ÙŠÙˆØ¬Ø¯'
        
        # Production Notes HTML
        notes = []
        
        if breakdown.cinematic_notes:
            notes.append(breakdown.cinematic_notes)
        
        if breakdown.continuity_notes:
            notes.extend(breakdown.continuity_notes)
        
        if breakdown.legal_alerts:
            notes.append('<br><ul class="bullets" style="margin-top:8px;">')
            for alert in breakdown.legal_alerts:
                notes.append(f'<li class="alert-text">âš ï¸ {alert.description}</li>')
            notes.append('</ul>')
        
        breakdown.production_notes_html = '<br>'.join(notes) if notes \
            else 'Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„Ø±Ø§ÙƒÙˆØ±Ø§Øª (Continuity)'
    
    async def _final_validation(self, breakdown: DetailedBreakdown):
        """ØªØ¯Ù‚ÙŠÙ‚ Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        if not breakdown.summary:
            breakdown.summary = "Ù…Ù„Ø®Øµ ØºÙŠØ± Ù…ØªÙˆÙØ±"
        
        if not breakdown.cast:
            breakdown.cast = []
        
        if not breakdown.camera_lighting:
            breakdown.camera_lighting = self._generate_camera_lighting(breakdown)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù…ÙÙ†Ø´Ø¦ HTML Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ (HTML Renderer)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HTMLRenderer:
    """Ù…ÙÙ†Ø´Ø¦ HTML Ø§Ø­ØªØ±Ø§ÙÙŠ"""
    
    CSS = """
    @page { size: A4; margin: 12mm; }
    
    :root{
      --ink:#111;
      --muted:#666;
      --soft:#f3f4f6;
      --soft2:#fafafa;
      --accent:#0f172a;
      --line: rgba(0,0,0,0.16);
      --line2: rgba(0,0,0,0.10);
      --tagbg:#eef2ff;
      --tagbd:#c7d2fe;
      --tagtx:#1e3a8a;
    }
    
    html, body {
      padding: 0;
      margin: 0;
      color: var(--ink);
      background: var(--soft2);
      font-family: "Tahoma", "Arial", sans-serif;
      -webkit-print-color-adjust: exact;
      print-color-adjust: exact;
    }
    
    body{ counter-reset: page; }
    
    .sheet {
      counter-increment: page;
      width: 210mm;
      min-height: 297mm;
      margin: 12px auto;
      background: #fff;
      box-shadow: 0 10px 28px rgba(0,0,0,0.10);
      border: 1px solid rgba(0,0,0,0.12);
      border-radius: 10px;
      box-sizing: border-box;
      padding: 12mm;
      display: flex;
      flex-direction: column;
      gap: 10px;
      break-after: page;
      page-break-after: always;
    }
    .sheet:last-child{
      break-after: auto;
      page-break-after: auto;
    }
    
    .sheet-header{
      border: 1px solid rgba(0,0,0,0.15);
      border-radius: 10px;
      padding: 10px 12px;
      background: linear-gradient(180deg, #ffffff 0%, #f7f7f7 100%);
    }
    
    .sheet-header-top{
      display: flex;
      align-items: baseline;
      justify-content: space-between;
      gap: 10px;
      margin-bottom: 6px;
    }
    
    .sheet-title{
      font-size: 16px;
      font-weight: 800;
      letter-spacing: 0.2px;
      color: var(--accent);
    }
    
    .sheet-badge{
      font-size: 12px;
      font-weight: 700;
      padding: 4px 10px;
      border-radius: 999px;
      border: 1px solid rgba(0,0,0,0.15);
      background: #fff;
      color: var(--accent);
      white-space: nowrap;
    }
    
    .sheet-meta{
      display: grid;
      grid-template-columns: 1fr 1fr 1fr;
      gap: 6px 10px;
      font-size: 12px;
      color: var(--muted);
    }
    .meta-item{
      display: flex;
      gap: 6px;
      align-items: baseline;
      white-space: nowrap;
    }
    .meta-label{
      font-weight: 800;
      color: var(--ink);
    }
    
    .sheet-table{
      width: 100%;
      border-collapse: separate;
      border-spacing: 0;
      border: 1px solid var(--line);
      border-radius: 10px;
      overflow: hidden;
      font-size: 12.2px;
    }
    .sheet-table thead th{
      background: var(--soft);
      color: var(--accent);
      font-weight: 800;
      padding: 10px 10px;
      border-bottom: 1px solid var(--line);
    }
    .sheet-table td{
      padding: 9px 10px;
      border-bottom: 1px solid var(--line2);
      vertical-align: top;
      line-height: 1.45;
    }
    .sheet-table tbody tr:last-child td{ border-bottom: none; }
    .sheet-table td.field{
      width: 34%;
      background: #fbfbfb;
      font-weight: 800;
      color: var(--accent);
      border-left: 1px solid var(--line2);
    }
    .sheet-table td.value{
      width: 66%;
      color: var(--ink);
    }
    
    .tag{
      display: inline-block;
      font-size: 11px;
      font-weight: 800;
      padding: 2px 8px;
      border-radius: 999px;
      border: 1px solid var(--tagbd);
      background: var(--tagbg);
      color: var(--tagtx);
      margin-inline-start: 6px;
      white-space: nowrap;
    }
    
    .bullets{ margin: 0; padding: 0 18px 0 0; }
    .bullets li{ margin: 0 0 4px 0; }
    
    .muted{ color: var(--muted); font-weight: 700; }
    .alert-text{ color: #b91c1c; font-weight: 700; }
    
    .sheet-footer{
      margin-top: auto;
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 10px;
      padding-top: 8px;
      border-top: 1px dashed rgba(0,0,0,0.25);
      font-size: 11px;
      color: var(--muted);
    }
    .footer-strong{ color: var(--ink); font-weight: 800; }
    .page-num::before{ content: counter(page); }
    
    @media print{
      body{ background:#fff; }
      .sheet{
        margin: 0;
        width: auto;
        min-height: auto;
        border-radius: 0;
        box-shadow: none;
        border: none;
        padding: 0;
      }
      .sheet-header, .sheet-table{ border-color: rgba(0,0,0,0.25); }
    }
    """
    
    @staticmethod
    def render_scene(scene: DetailedBreakdown, total: int) -> str:
        """ØªØ­ÙˆÙŠÙ„ Ù…Ø´Ù‡Ø¯ ÙˆØ§Ø­Ø¯ Ø¥Ù„Ù‰ HTML"""
        
        def esc(s: str) -> str:
            return html.escape(s or "", quote=True)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Cast
        cast_text = "ØŒ ".join(scene.cast) if scene.cast else ""
        cast_html = esc(cast_text) if cast_text else '<span class="muted">ØºÙŠØ± Ù…Ø°ÙƒÙˆØ±</span>'
        
        return f"""
  <section class="sheet">
    <header class="sheet-header">
      <div class="sheet-header-top">
        <div class="sheet-title">Breakdown Sheet â€” Ù…Ø´Ù‡Ø¯ {esc(scene.scene_number)}</div>
        <div class="sheet-badge">A4 Ready</div>
      </div>
      <div class="sheet-meta">
        <div class="meta-item"><span class="meta-label">INT/EXT:</span><span>{esc(scene.int_ext)}</span></div>
        <div class="meta-item"><span class="meta-label">Ù†Ù‡Ø§Ø±/Ù„ÙŠÙ„:</span><span>{esc(scene.day_night)}</span></div>
        <div class="meta-item"><span class="meta-label">Ø§Ù„Ù…ÙˆÙ‚Ø¹:</span><span>{esc(scene.location)}</span></div>
      </div>
    </header>

    <table class="sheet-table">
      <thead><tr><th>Ø§Ù„Ø­Ù‚Ù„</th><th>Ø§Ù„ØªÙØ§ØµÙŠÙ„</th></tr></thead>
      <tbody>
        <tr><td class="field">Ø±Ù‚Ù… Ø§Ù„Ù…Ø´Ù‡Ø¯</td><td class="value">{esc(scene.scene_number)}</td></tr>
        <tr><td class="field">Ù…Ù„Ø®Øµ Ø§Ù„Ø­Ø¯Ø«</td><td class="value">{esc(scene.summary)}</td></tr>

        <tr><td class="field">Ø·Ø§Ù‚Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ / Cast</td><td class="value">{cast_html}</td></tr>
        <tr><td class="field">Ø§Ù„Ù…Ù…Ø«Ù„ÙˆÙ† Ø§Ù„Ø¥Ø¶Ø§ÙÙŠÙˆÙ† / Extras</td><td class="value">{scene.extras_html}</td></tr>

        <tr><td class="field">Ø§Ù„Ø£Ø²ÙŠØ§Ø¡ / Costumes</td><td class="value">{scene.costumes_html}</td></tr>
        <tr><td class="field">Ø§Ù„Ù…ÙƒÙŠØ§Ø¬ / Makeup</td><td class="value">{scene.makeup_html}</td></tr>

        <tr><td class="field">Ø§Ù„Ø¯Ø¹Ø§Ø¦Ù… / Props</td><td class="value">{scene.props_html}</td></tr>
        <tr><td class="field">Ø¯ÙŠÙƒÙˆØ±Ø§Øª Ø§Ù„Ù…ÙˆÙ‚Ø¹ / Set Dressings</td><td class="value">{scene.set_dressing_html}</td></tr>

        <tr><td class="field">Ø§Ù„Ø­ÙŠÙˆØ§Ù†Ø§Øª / Animals</td><td class="value">{esc(scene.animals)}</td></tr>
        <tr><td class="field">Ø§Ù„Ù…Ø±ÙƒØ¨Ø§Øª / Vehicles</td><td class="value">{esc(scene.vehicles)}</td></tr>
        <tr><td class="field">Ø§Ù„Ù…Ø³Ø§Ø­Ø§Øª Ø§Ù„Ø®Ø¶Ø±Ø§Ø¡ / Greenery</td><td class="value">{esc(scene.greenery)}</td></tr>
        <tr><td class="field">Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ø®Ø·Ø±Ø© / Stunts</td><td class="value">{esc(scene.stunts)}</td></tr>

        <tr><td class="field">Ø§Ù„Ù…Ø¤Ø«Ø±Ø§Øª Ø§Ù„Ø®Ø§ØµØ© / Special Effects</td><td class="value">{scene.special_effects_html}</td></tr>
        <tr><td class="field">Ø§Ù„Ù…Ø¤Ø«Ø±Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© / Visual Effects</td><td class="value">{esc(scene.visual_effects)}</td></tr>

        <tr><td class="field">Ø§Ù„ØµÙˆØª / Sound</td><td class="value">{scene.sound_html}</td></tr>
        <tr><td class="field">Ø§Ù„ØªØµÙˆÙŠØ± ÙˆØ§Ù„Ø¥Ø¶Ø§Ø¡Ø© / Camera & Lighting</td><td class="value">{esc(scene.camera_lighting)}</td></tr>

        <tr><td class="field">Ù…Ù„Ø§Ø­Ø¸Ø§Øª (Wardrobe/Notes)</td><td class="value">{scene.production_notes_html}</td></tr>
      </tbody>
    </table>

    <footer class="sheet-footer">
      <div><span class="footer-strong">Breakdown Sheets</span> â€” Scenes 1â€“{total}</div>
      <div>ØµÙØ­Ø©: <span class="footer-strong page-num"></span> / {total}</div>
    </footer>
  </section>
"""
    
    @staticmethod
    def render_full_document(scenes: List[DetailedBreakdown]) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø§Ù„ÙƒØ§Ù…Ù„"""
        total = len(scenes)
        scenes_html = "".join([
            HTMLRenderer.render_scene(s, total) for s in scenes
        ])
        
        return f"""<!doctype html>
<html lang="ar" dir="rtl">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Breakdown Sheets â€” Scenes 1â€“{total}</title>
  <style>{HTMLRenderer.CSS}</style>
</head>
<body>
{scenes_html}
</body>
</html>"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© (Utilities)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def split_scenes(content: str) -> List[Tuple[str, str]]:
    """
    ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ Ø¥Ù„Ù‰ Ù…Ø´Ø§Ù‡Ø¯
    
    Returns:
        Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† (scene_number, scene_text)
    """
    pattern = re.compile(r'(?=^\s*(?:Ù…Ø´Ù‡Ø¯|scene)\s*\d+)', re.I | re.M)
    blocks = [b.strip() for b in pattern.split(content) if b.strip()]
    
    scenes = []
    num_pattern = re.compile(r'^\s*(?:Ù…Ø´Ù‡Ø¯|scene)\s*(\d+)', re.I)
    
    for block in blocks:
        match = num_pattern.search(block)
        if match:
            scenes.append((match.group(1), block))
    
    return scenes


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Main Function)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main_async(input_path: str, output_path: str):
    """
    Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ
    """
    logger.info("â•" * 70)
    logger.info("Ø¨Ø¯Ø¡ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ...")
    logger.info("â•" * 70)
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù
    try:
        if ASYNC_FILES_AVAILABLE:
            async with aiofiles.open(input_path, 'r', encoding='utf-8') as f:
                content = await f.read()
        else:
            with open(input_path, 'r', encoding='utf-8') as f:
                content = f.read()
        
        logger.info(f"âœ“ ØªÙ… Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {input_path}")
    except FileNotFoundError:
        logger.error(f"âŒ Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {input_path}")
        raise
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù: {e}")
        raise
    
    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯
    scenes_data = split_scenes(content)
    if not scenes_data:
        logger.error("âŒ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø´Ø§Ù‡Ø¯ ÙÙŠ Ø§Ù„Ù…Ù„Ù")
        raise ValueError("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø´Ø§Ù‡Ø¯")
    
    logger.info(f"âœ“ ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {len(scenes_data)} Ù…Ø´Ù‡Ø¯")
    logger.info("â•" * 70)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø­Ù„Ù„
    parser = RevolutionarySceneParser()
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯
    scenes = []
    for scene_num, scene_text in scenes_data:
        try:
            breakdown = await parser.analyze_scene(scene_text, scene_num)
            scenes.append(breakdown)
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø´Ù‡Ø¯ {scene_num}: {e}")
            # Ø§Ø³ØªÙ…Ø±Ø§Ø± ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    
    logger.info("â•" * 70)
    logger.info(f"âœ“ ØªÙ… ØªØ­Ù„ÙŠÙ„ {len(scenes)}/{len(scenes_data)} Ù…Ø´Ù‡Ø¯ Ø¨Ù†Ø¬Ø§Ø­")
    logger.info("â•" * 70)
    
    # ØªÙˆÙ„ÙŠØ¯ HTML
    logger.info("ğŸ“ ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ù HTML...")
    html_doc = HTMLRenderer.render_full_document(scenes)
    
    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù
    try:
        if ASYNC_FILES_AVAILABLE:
            async with aiofiles.open(output_path, 'w', encoding='utf-8') as f:
                await f.write(html_doc)
        else:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_doc)
        
        logger.info(f"âœ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {output_path}")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {e}")
        raise
    
    logger.info("â•" * 70)
    logger.info("ğŸ‰ Case Closed: ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­")
    logger.info("â•" * 70)


def main(input_path: Optional[str] = None, output_path: Optional[str] = None):
    """
    Ù†Ù‚Ø·Ø© Ø§Ù„Ø¯Ø®ÙˆÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    """
    # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    if input_path is None:
        input_path = r"E:\agents\script.txt"
    
    if output_path is None:
        output_path = "revolutionary_breakdown_sheets.html"
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
    input_file = Path(input_path)
    if not input_file.exists():
        logger.error(f"âŒ Ù…Ù„Ù Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {input_path}")
        logger.info("ğŸ’¡ ØªØ£ÙƒØ¯ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù…Ø³Ø§Ø± Ø£Ùˆ Ù…Ø±Ø± Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ù„Ù ÙƒÙ€ argument")
        return
    
    # ØªØ´ØºÙŠÙ„ async
    try:
        asyncio.run(main_async(input_path, output_path))
    except KeyboardInterrupt:
        logger.warning("âš ï¸ ØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
        raise


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© (Entry Point)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import sys
    
    # Ø¯Ø¹Ù… ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ÙƒÙ€ arguments
    if len(sys.argv) >= 2:
        input_arg = sys.argv[1]
        output_arg = sys.argv[2] if len(sys.argv) >= 3 else None
        main(input_arg, output_arg)
    else:
        # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        main()